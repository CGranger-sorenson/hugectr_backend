{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "498adc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a73d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/hps_demo\u001b[00m\n",
      "└── \u001b[01;34membedding\u001b[00m\n",
      "    └── \u001b[01;34mhps_infer\u001b[00m\n",
      "        └── \u001b[01;34m1\u001b[00m\n",
      "\n",
      "3 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree -l /hps_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83514f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/hps_demo\u001b[00m\n",
      "└── \u001b[01;34membedding\u001b[00m\n",
      "    └── \u001b[01;34mhps_infer\u001b[00m\n",
      "        └── \u001b[01;34m1\u001b[00m\n",
      "            ├── \u001b[01;34mhps_train0_sparse_1000.model\u001b[00m\n",
      "            │   ├── emb_vector\n",
      "            │   └── key\n",
      "            └── \u001b[01;34mhps_train1_sparse_1000.model\u001b[00m\n",
      "                ├── emb_vector\n",
      "                └── key\n",
      "\n",
      "5 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "!cp -r ./hps_train0_sparse_1000.model /hps_demo/embedding/hps_infer/1\n",
    "!cp -r ./hps_train1_sparse_1000.model /hps_demo/embedding/hps_infer/1\n",
    "!tree -l /hps_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "015feeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./hps_demo/embedding/hps_infer/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hps_demo/embedding/hps_infer/config.pbtxt\n",
    "name: \"hps_demo\"\n",
    "backend: \"hps\"\n",
    "max_batch_size:1024,\n",
    "input [\n",
    "  {\n",
    "    name: \"KEYS\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"NUMKEYS\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "version_policy: {\n",
    "        specific:{versions: 1}\n",
    "},\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe61560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /hps_demo/embedding/hps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hps_demo/embedding/hps.json\n",
    "{\n",
    "    \"supportlonglong\": true,\n",
    "    \"volatile_db\": {\n",
    "        \"type\": \"hash_map\",\n",
    "        \"user_name\": \"default\",\n",
    "        \"num_partitions\": 8,\n",
    "        \"max_get_batch_size\": 100000,\n",
    "        \"max_set_batch_size\": 100000,\n",
    "        \"overflow_policy\": \"evict_oldest\",\n",
    "        \"overflow_margin\": 10000000,\n",
    "        \"overflow_resolution_target\": 0.8,\n",
    "        \"initial_cache_rate\": 1.0\n",
    "    },\n",
    "    \"persistent_db\": {\n",
    "        \"type\": \"disabled\"\n",
    "    },\n",
    "    \"models\": [{\n",
    "        \"model\": \"hps_train\",\n",
    "        \"sparse_files\": [\"/hps_demo/embedding/hps_infer/1/hps_train0_sparse_1000.model\", \"/hps_demo/embedding/hps_infer/1/hps_train1_sparse_1000.model\"],\n",
    "        \"num_of_worker_buffer_in_pool\": 3,\n",
    "        \"embedding_table_names\":[\"embedding_table1\",\"embedding_table2\"],\n",
    "        \"embedding_vecsize_per_table\":[1,16],\n",
    "        \"maxnum_catfeature_query_per_table_per_sample\":[2,26],\n",
    "        \"default_value_for_each_table\":[0.0,0.0],\n",
    "        \"deployed_device_list\":[0],\n",
    "        \"max_batch_size\":1024,\n",
    "        \"cache_refresh_percentage_per_iteration\":0.2,\n",
    "        \"hit_rate_threshold\":0.9,\n",
    "        \"gpucacheper\":0.5,\n",
    "        \"gpucache\":true\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "# model.fit(max_iter = 1100, display = 200, eval_interval = 1000, snapshot = 1000, snapshot_prefix = \"hps_train\")\n",
    "# solver = hugectr.CreateSolver(model_name = \"hps_train\",\n",
    "#                               max_eval_batches = 1,\n",
    "#                               batchsize_eval = 1024,\n",
    "#                               batchsize = 1024,\n",
    "#                               lr = 0.001,\n",
    "#                               vvgpu = [[0]],\n",
    "#                               i64_input_key = True,\n",
    "#                               repeat_dataset = True,\n",
    "#                               use_cuda_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638c06fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./hps_demo\u001b[00m\n",
      "└── \u001b[01;34membedding\u001b[00m\n",
      "    └── \u001b[01;34mhps_infer\u001b[00m\n",
      "        ├── \u001b[01;34m1\u001b[00m\n",
      "        │   ├── \u001b[01;34mhps_train0_sparse_1000.model\u001b[00m\n",
      "        │   │   ├── emb_vector\n",
      "        │   │   └── key\n",
      "        │   └── \u001b[01;34mhps_train1_sparse_1000.model\u001b[00m\n",
      "        │       ├── emb_vector\n",
      "        │       └── key\n",
      "        └── config.pbtxt\n",
      "\n",
      "5 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree -l ./hps_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01375ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/hps_infer/embedding\u001b[00m\n",
      "├── hps.json\n",
      "├── \u001b[01;34mhps_ensemble\u001b[00m\n",
      "│   └── \u001b[01;34m1\u001b[00m\n",
      "├── \u001b[01;34mhps_torch\u001b[00m\n",
      "│   └── \u001b[01;34m1\u001b[00m\n",
      "└── \u001b[01;34mhps_wdl\u001b[00m\n",
      "    ├── \u001b[01;34m1\u001b[00m\n",
      "    │   ├── \u001b[01;34mwdl0_sparse_20000.model\u001b[00m\n",
      "    │   │   ├── emb_vector\n",
      "    │   │   ├── key\n",
      "    │   │   ├── wdl0_sparse_20000.model.key\n",
      "    │   │   └── wdl0_sparse_20000.model.vec\n",
      "    │   └── \u001b[01;34mwdl1_sparse_20000.model\u001b[00m\n",
      "    │       ├── emb_vector\n",
      "    │       ├── key\n",
      "    │       ├── wdl1_sparse_20000.model.key\n",
      "    │       └── wdl1_sparse_20000.model.vec\n",
      "    └── config.pbtxt\n",
      "\n",
      "8 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "!tree /hps_infer/embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tritonserver --model-repository=/wdl_infer/model/ --load-model=wdl \\\n",
    "#     --model-control-mode=explicit \\ \n",
    "#     --backend-directory=/usr/local/hugectr/backends \\\n",
    "#     --backend-config=hugectr,ps=/wdl_infer/model/ps.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a2d6067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0616 04:50:20.847500 14892 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7fdc46000000' with size 268435456\n",
      "I0616 04:50:20.903912 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0616 04:50:20.903923 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 1 with size 67108864\n",
      "I0616 04:50:20.903932 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 2 with size 67108864\n",
      "I0616 04:50:20.903938 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 3 with size 67108864\n",
      "I0616 04:50:20.903945 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 4 with size 67108864\n",
      "I0616 04:50:20.903949 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 5 with size 67108864\n",
      "I0616 04:50:20.903955 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 6 with size 67108864\n",
      "I0616 04:50:20.903959 14892 cuda_memory_manager.cc:105] CUDA memory pool is created on device 7 with size 67108864\n",
      "I0616 04:50:22.770726 14892 model_repository_manager.cc:997] loading: hps_wdl:1\n",
      "I0616 04:50:22.884687 14892 hps.cc:61] TRITONBACKEND_Initialize: hps\n",
      "I0616 04:50:22.884708 14892 hps.cc:68] Triton TRITONBACKEND API version: 1.8\n",
      "I0616 04:50:22.884714 14892 hps.cc:72] 'hps' TRITONBACKEND API version: 1.8\n",
      "I0616 04:50:22.884722 14892 hps.cc:95] The Hierarchical Parameter Server Backend Repository location: /usr/local/hugectr/backends/hps\n",
      "I0616 04:50:22.884728 14892 hps.cc:106] The HPS configuration: {\"cmdline\":{\"ps\":\"/hps_infer/embedding/hps.json\"}}\n",
      "I0616 04:50:22.884746 14892 backend.cpp:62] *****The Hierarchical Parameter Server is creating... *****\n",
      "I0616 04:50:22.884751 14892 backend.cpp:65] ***** Hierarchical Parameter Server(Int64) is creating... *****\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: path is not specified using default: /tmp/rocksdb\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: num_threads is not specified using default: 16\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: read_only is not specified using default: 0\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: max_get_batch_size is not specified using default: 10000\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: max_set_batch_size is not specified using default: 10000\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: address is not specified using default: 127.0.0.1:7000\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: password is not specified using default: \n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: refresh_time_after_fetch is not specified using default: 0\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: cache_missed_embeddings is not specified using default: 0\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: dense_file is not specified using default: \n",
      "[HCTR][04:50:22.884][WARNING][RK0][main]: default_value_for_each_table.size() is not equal to the number of embedding tables\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: num_of_refresher_buffer_in_pool is not specified using default: 1\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: maxnum_des_feature_per_sample is not specified using default: 26\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: refresh_delay is not specified using default: 0\n",
      "[HCTR][04:50:22.884][INFO][RK0][main]: refresh_interval is not specified using default: 0\n",
      "[HCTR][04:50:22.885][INFO][RK0][main]: Creating HashMap CPU database backend...\n",
      "[HCTR][04:50:22.885][WARNING][RK0][main]: Setting 'num_partitions' = 8 is not supported by the non-parallelized HashTable backend and will be ignored.\n",
      "[HCTR][04:50:22.885][INFO][RK0][main]: Created blank database backend in local memory!\n",
      "[HCTR][04:50:22.885][INFO][RK0][main]: Volatile DB: initial cache rate = 1\n",
      "[HCTR][04:50:22.885][INFO][RK0][main]: Volatile DB: cache missed embeddings = 0\n",
      "[HCTR][04:50:22.927][DEBUG][RK0][main]: HashMap backend. Table: hps_et.hps_wdl.embedding_table1. Inserted 268619 / 268619 pairs.\n",
      "[HCTR][04:50:22.927][INFO][RK0][main]: Table: hps_et.hps_wdl.embedding_table1; cached 268619 / 268619 embeddings in volatile database (HashMap); load: 268619 / 10000000 (2.69%).\n",
      "[HCTR][04:50:23.432][DEBUG][RK0][main]: HashMap backend. Table: hps_et.hps_wdl.embedding_table2. Inserted 1869965 / 1869965 pairs.\n",
      "[HCTR][04:50:23.432][INFO][RK0][main]: Table: hps_et.hps_wdl.embedding_table2; cached 1869965 / 1869965 embeddings in volatile database (HashMap); load: 1869965 / 10000000 (18.70%).\n",
      "[HCTR][04:50:23.437][DEBUG][RK0][main]: Real-time subscribers created!\n",
      "[HCTR][04:50:23.437][INFO][RK0][main]: Create embedding cache in device 0.\n",
      "[HCTR][04:50:23.438][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 0.500000\n",
      "[HCTR][04:50:23.438][INFO][RK0][main]: Configured cache hit rate threshold: 0.900000\n",
      "I0616 04:50:23.576401 14892 backend.cpp:73] *****The Hierarchaical Prameter Server has been created successfully! *****\n",
      "I0616 04:50:23.576464 14892 hps.cc:169] TRITONBACKEND_ModelInitialize: hps_wdl (version 1)\n",
      "I0616 04:50:23.576471 14892 hps.cc:182] Repository location: /hps_infer/embedding/hps_wdl\n",
      "I0616 04:50:23.576476 14892 hps.cc:197] backend configuration in mode: {\"cmdline\":{\"ps\":\"/hps_infer/embedding/hps.json\"}}\n",
      "I0616 04:50:23.577318 14892 model_state.cpp:129] Verifying model configuration: {\n",
      "    \"name\": \"hps_wdl\",\n",
      "    \"platform\": \"\",\n",
      "    \"backend\": \"hps\",\n",
      "    \"version_policy\": {\n",
      "        \"specific\": {\n",
      "            \"versions\": [\n",
      "                1\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"max_batch_size\": 1024,\n",
      "    \"input\": [\n",
      "        {\n",
      "            \"name\": \"KEYS\",\n",
      "            \"data_type\": \"TYPE_INT64\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false,\n",
      "            \"optional\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"NUMKEYS\",\n",
      "            \"data_type\": \"TYPE_INT32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false,\n",
      "            \"optional\": false\n",
      "        }\n",
      "    ],\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"name\": \"OUTPUT0\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"label_filename\": \"\",\n",
      "            \"is_shape_tensor\": false\n",
      "        }\n",
      "    ],\n",
      "    \"batch_input\": [],\n",
      "    \"batch_output\": [],\n",
      "    \"optimization\": {\n",
      "        \"priority\": \"PRIORITY_DEFAULT\",\n",
      "        \"input_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"output_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"gather_kernel_buffer_threshold\": 0,\n",
      "        \"eager_batching\": false\n",
      "    },\n",
      "    \"instance_group\": [\n",
      "        {\n",
      "            \"name\": \"hps_wdl_0\",\n",
      "            \"kind\": \"KIND_GPU\",\n",
      "            \"count\": 1,\n",
      "            \"gpus\": [\n",
      "                0\n",
      "            ],\n",
      "            \"secondary_devices\": [],\n",
      "            \"profile\": [],\n",
      "            \"passive\": false,\n",
      "            \"host_policy\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"default_model_filename\": \"\",\n",
      "    \"cc_model_filenames\": {},\n",
      "    \"metric_tags\": {},\n",
      "    \"parameters\": {},\n",
      "    \"model_warmup\": []\n",
      "}\n",
      "I0616 04:50:23.577418 14892 model_state.cpp:210] The model configuration: {\n",
      "    \"name\": \"hps_wdl\",\n",
      "    \"platform\": \"\",\n",
      "    \"backend\": \"hps\",\n",
      "    \"version_policy\": {\n",
      "        \"specific\": {\n",
      "            \"versions\": [\n",
      "                1\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"max_batch_size\": 1024,\n",
      "    \"input\": [\n",
      "        {\n",
      "            \"name\": \"KEYS\",\n",
      "            \"data_type\": \"TYPE_INT64\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false,\n",
      "            \"optional\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"NUMKEYS\",\n",
      "            \"data_type\": \"TYPE_INT32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false,\n",
      "            \"optional\": false\n",
      "        }\n",
      "    ],\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"name\": \"OUTPUT0\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"label_filename\": \"\",\n",
      "            \"is_shape_tensor\": false\n",
      "        }\n",
      "    ],\n",
      "    \"batch_input\": [],\n",
      "    \"batch_output\": [],\n",
      "    \"optimization\": {\n",
      "        \"priority\": \"PRIORITY_DEFAULT\",\n",
      "        \"input_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"output_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"gather_kernel_buffer_threshold\": 0,\n",
      "        \"eager_batching\": false\n",
      "    },\n",
      "    \"instance_group\": [\n",
      "        {\n",
      "            \"name\": \"hps_wdl_0\",\n",
      "            \"kind\": \"KIND_GPU\",\n",
      "            \"count\": 1,\n",
      "            \"gpus\": [\n",
      "                0\n",
      "            ],\n",
      "            \"secondary_devices\": [],\n",
      "            \"profile\": [],\n",
      "            \"passive\": false,\n",
      "            \"host_policy\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"default_model_filename\": \"\",\n",
      "    \"cc_model_filenames\": {},\n",
      "    \"metric_tags\": {},\n",
      "    \"parameters\": {},\n",
      "    \"model_warmup\": []\n",
      "}\n",
      "I0616 04:50:23.577479 14892 model_state.cpp:308] ******Creating Embedding Cache for model hps_wdl in device 0\n",
      "I0616 04:50:23.577485 14892 model_state.cpp:318] ******Creating Embedding Cache for model hps_wdl successfully\n",
      "I0616 04:50:23.585995 14892 hps.cc:307] TRITONBACKEND_ModelInstanceInitialize: hps_wdl_0 (device 0)\n",
      "I0616 04:50:23.586009 14892 model_instance_state.cpp:81] Triton Model Instance Initialization on device 0\n",
      "I0616 04:50:23.595197 14892 model_instance_state.cpp:91] Categorical Feature buffer allocation: \n",
      "I0616 04:50:23.595257 14892 model_instance_state.cpp:99] Number of Categorical Feature per Table buffer allocation: \n",
      "I0616 04:50:23.595289 14892 model_instance_state.cpp:109] Look_up result buffer allocation: \n",
      "I0616 04:50:23.595332 14892 hps.cc:320] ******Loading HPS ******\n",
      "I0616 04:50:23.595338 14892 model_instance_state.cpp:140] The model origin json configuration file path is: \n",
      "[HCTR][04:50:23.595][INFO][RK0][main]: Create inference session on device: 0\n",
      "[HCTR][04:50:23.595][INFO][RK0][main]: Model name: hps_wdl\n",
      "[HCTR][04:50:23.595][INFO][RK0][main]: Number of embedding tables: 2\n",
      "[HCTR][04:50:23.595][INFO][RK0][main]: Use I64 input key: True\n",
      "I0616 04:50:23.595379 14892 model_instance_state.cpp:147] ******Loading HugeCTR lookup session successfully\n",
      "I0616 04:50:23.595594 14892 model_repository_manager.cc:1152] successfully loaded 'hps_wdl' version 1\n",
      "I0616 04:50:23.595650 14892 server.cc:524] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0616 04:50:23.595683 14892 server.cc:551] \n",
      "+---------+---------------------------------+---------------------------------+\n",
      "| Backend | Path                            | Config                          |\n",
      "+---------+---------------------------------+---------------------------------+\n",
      "| hps     | /usr/local/hugectr/backends/hps | {\"cmdline\":{\"ps\":\"/hps_infer/em |\n",
      "|         | /libtriton_hps.so               | bedding/hps.json\"}}             |\n",
      "+---------+---------------------------------+---------------------------------+\n",
      "\n",
      "I0616 04:50:23.595711 14892 server.cc:594] \n",
      "+---------+---------+--------+\n",
      "| Model   | Version | Status |\n",
      "+---------+---------+--------+\n",
      "| hps_wdl | 1       | READY  |\n",
      "+---------+---------+--------+\n",
      "\n",
      "I0616 04:50:23.846644 14892 metrics.cc:651] Collecting metrics for GPU 0: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.846686 14892 metrics.cc:651] Collecting metrics for GPU 1: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.846697 14892 metrics.cc:651] Collecting metrics for GPU 2: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.846706 14892 metrics.cc:651] Collecting metrics for GPU 3: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.846715 14892 metrics.cc:651] Collecting metrics for GPU 4: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.846725 14892 metrics.cc:651] Collecting metrics for GPU 5: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.846734 14892 metrics.cc:651] Collecting metrics for GPU 6: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.846743 14892 metrics.cc:651] Collecting metrics for GPU 7: NVIDIA A100-SXM4-80GB\n",
      "I0616 04:50:23.851528 14892 tritonserver.cc:1962] \n",
      "+----------------------------------+------------------------------------------+\n",
      "| Option                           | Value                                    |\n",
      "+----------------------------------+------------------------------------------+\n",
      "| server_id                        | triton                                   |\n",
      "| server_version                   | 2.20.0                                   |\n",
      "| server_extensions                | classification sequence model_repository |\n",
      "|                                  |  model_repository(unload_dependents) sch |\n",
      "|                                  | edule_policy model_configuration system_ |\n",
      "|                                  | shared_memory cuda_shared_memory binary_ |\n",
      "|                                  | tensor_data statistics trace             |\n",
      "| model_repository_path[0]         | /hps_infer/embedding/                    |\n",
      "| model_control_mode               | MODE_EXPLICIT                            |\n",
      "| startup_models_0                 | hps_wdl                                  |\n",
      "| strict_model_config              | 1                                        |\n",
      "| rate_limit                       | OFF                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{1}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{2}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{3}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{4}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{5}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{6}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{7}    | 67108864                                 |\n",
      "| response_cache_byte_size         | 0                                        |\n",
      "| min_supported_compute_capability | 6.0                                      |\n",
      "| strict_readiness                 | 1                                        |\n",
      "| exit_timeout                     | 30                                       |\n",
      "+----------------------------------+------------------------------------------+\n",
      "\n",
      "I0616 04:50:23.852767 14892 grpc_server.cc:4421] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0616 04:50:23.852991 14892 http_server.cc:3113] Started HTTPService at 0.0.0.0:8000\n",
      "I0616 04:50:23.894126 14892 http_server.cc:178] Started Metrics Service at 0.0.0.0:8002\n",
      "^C\n",
      "Signal (2) received.\n",
      "I0616 04:51:52.841875 14892 server.cc:252] Waiting for in-flight requests to complete.\n",
      "I0616 04:51:52.841893 14892 model_repository_manager.cc:1029] unloading: hps_wdl:1\n",
      "I0616 04:51:52.842012 14892 server.cc:267] Timeout 30: Found 1 live models and 0 in-flight non-inference requests\n",
      "I0616 04:51:52.842119 14892 hps.cc:337] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I0616 04:51:52.842799 14892 hps.cc:268] TRITONBACKEND_ModelFinalize: delete model state\n",
      "I0616 04:51:52.882851 14892 model_state.cpp:112] ******Destorying Embedding Cache for model hps_wdl successfully\n",
      "I0616 04:51:52.882868 14892 hps.cc:150] TRITONBACKEND_Backend Finalize: HPSBackend\n"
     ]
    }
   ],
   "source": [
    "!tritonserver --model-repository=/hps_infer/embedding/ --load-model=hps_wdl \\\n",
    "    --model-control-mode=explicit \\\n",
    "    --backend-directory=/usr/local/hugectr/backends \\\n",
    "    --backend-config=hps,ps=/hps_infer/embedding/hps.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4885c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b6797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc9aa152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:8000...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\n",
      "> GET /v2/health/ready HTTP/1.1\n",
      "> Host: localhost:8000\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Length: 0\n",
      "< Content-Type: text/plain\n",
      "< \n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c3f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f1344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f41dcc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 232\n",
      "-rw-r--r-- 1 root root  25720 Jun 16 05:07 test.parquet\n",
      "-rw-r--r-- 1 root root 176913 Jun 16 05:07 train.parquet\n",
      "-rw-r--r-- 1 root root  25007 Jun 16 05:06 valid.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l /wdl_train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7ba76db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id-count</th>\n",
       "      <th>session_id</th>\n",
       "      <th>category-list_trim</th>\n",
       "      <th>item_id-list_trim</th>\n",
       "      <th>timestamp/age_days-list_trim</th>\n",
       "      <th>timestamp/weekday/sin-list_trim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>[10, 16, 2, 9, 7, 2, 5, 2, 3, 20, 12, 5, 7, 8,...</td>\n",
       "      <td>[42, 73, 7, 31, 29, 4, 18, 6, 9, 93, 45, 15, 2...</td>\n",
       "      <td>[0.09185880216576592, 0.8937236602103082, 0.54...</td>\n",
       "      <td>[0.5701232580182504, 0.19997826182734457, 0.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>136</td>\n",
       "      <td>[2, 10, 6, 2, 3, 9, 2, 2, 5, 10, 17, 3, 2, 9, ...</td>\n",
       "      <td>[6, 43, 22, 4, 14, 36, 7, 4, 17, 40, 75, 9, 4,...</td>\n",
       "      <td>[0.6626862922002159, 0.6376980627004402, 0.511...</td>\n",
       "      <td>[0.6466013947223641, 0.015085043467372605, 0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>174</td>\n",
       "      <td>[6, 26, 2, 3, 6, 3, 15, 9, 2, 7, 10, 6, 5, 3, ...</td>\n",
       "      <td>[20, 107, 2, 8, 20, 14, 61, 31, 2, 28, 40, 22,...</td>\n",
       "      <td>[0.9958805890923509, 0.5608152309433158, 0.931...</td>\n",
       "      <td>[0.9306965631914249, 0.17375987258739167, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17</td>\n",
       "      <td>241</td>\n",
       "      <td>[9, 9, 4, 25, 6, 5, 5, 3, 5, 2, 2, 8, 4, 9, 9,...</td>\n",
       "      <td>[31, 31, 13, 132, 22, 15, 18, 14, 18, 2, 3, 39...</td>\n",
       "      <td>[0.31851696556214915, 0.20042394643567374, 0.3...</td>\n",
       "      <td>[0.0453928651276444, 0.5975708077512965, 0.816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>335</td>\n",
       "      <td>[2, 9, 11, 20, 10, 11, 14, 9, 10, 3, 4, 4, 44,...</td>\n",
       "      <td>[7, 32, 50, 83, 41, 52, 63, 32, 40, 8, 13, 21,...</td>\n",
       "      <td>[0.6629638255783589, 0.8477154189923084, 0.421...</td>\n",
       "      <td>[0.5507906588971854, 0.4802218018859009, 0.580...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id-count  session_id  \\\n",
       "3              19          59   \n",
       "14             17         136   \n",
       "21             17         174   \n",
       "30             17         241   \n",
       "39             16         335   \n",
       "\n",
       "                                   category-list_trim  \\\n",
       "3   [10, 16, 2, 9, 7, 2, 5, 2, 3, 20, 12, 5, 7, 8,...   \n",
       "14  [2, 10, 6, 2, 3, 9, 2, 2, 5, 10, 17, 3, 2, 9, ...   \n",
       "21  [6, 26, 2, 3, 6, 3, 15, 9, 2, 7, 10, 6, 5, 3, ...   \n",
       "30  [9, 9, 4, 25, 6, 5, 5, 3, 5, 2, 2, 8, 4, 9, 9,...   \n",
       "39  [2, 9, 11, 20, 10, 11, 14, 9, 10, 3, 4, 4, 44,...   \n",
       "\n",
       "                                    item_id-list_trim  \\\n",
       "3   [42, 73, 7, 31, 29, 4, 18, 6, 9, 93, 45, 15, 2...   \n",
       "14  [6, 43, 22, 4, 14, 36, 7, 4, 17, 40, 75, 9, 4,...   \n",
       "21  [20, 107, 2, 8, 20, 14, 61, 31, 2, 28, 40, 22,...   \n",
       "30  [31, 31, 13, 132, 22, 15, 18, 14, 18, 2, 3, 39...   \n",
       "39  [7, 32, 50, 83, 41, 52, 63, 32, 40, 8, 13, 21,...   \n",
       "\n",
       "                         timestamp/age_days-list_trim  \\\n",
       "3   [0.09185880216576592, 0.8937236602103082, 0.54...   \n",
       "14  [0.6626862922002159, 0.6376980627004402, 0.511...   \n",
       "21  [0.9958805890923509, 0.5608152309433158, 0.931...   \n",
       "30  [0.31851696556214915, 0.20042394643567374, 0.3...   \n",
       "39  [0.6629638255783589, 0.8477154189923084, 0.421...   \n",
       "\n",
       "                      timestamp/weekday/sin-list_trim  \n",
       "3   [0.5701232580182504, 0.19997826182734457, 0.24...  \n",
       "14  [0.6466013947223641, 0.015085043467372605, 0.7...  \n",
       "21  [0.9306965631914249, 0.17375987258739167, 0.07...  \n",
       "30  [0.0453928651276444, 0.5975708077512965, 0.816...  \n",
       "39  [0.5507906588971854, 0.4802218018859009, 0.580...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"/wdl_train/val/test.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d657952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d69fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
