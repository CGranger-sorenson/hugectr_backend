{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d102edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85eafbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnvironmental description\\nDocker: merlin_inference\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Environmental description\n",
    "Docker: merlin_inference\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83de1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224bfd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8c00713",
   "metadata": {},
   "source": [
    "## Global environment variable setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5804eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f6f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a5155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b715c0fa",
   "metadata": {},
   "source": [
    "## Create working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3d16e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/hps_demo\"\n",
    "embedding_folder  = os.path.join(BASE_DIR, \"embedding\")\n",
    "wdl_embedding_repo= os.path.join(embedding_folder, \"hps_infer\")\n",
    "wdl_version =os.path.join(wdl_embedding_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(embedding_folder):\n",
    "    shutil.rmtree(embedding_folder)\n",
    "os.makedirs(embedding_folder)\n",
    "\n",
    "if os.path.isdir(wdl_embedding_repo):\n",
    "    shutil.rmtree(wdl_embedding_repo)\n",
    "os.makedirs(wdl_embedding_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad30d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/hps_demo\u001b[00m\n",
      "└── \u001b[01;34membedding\u001b[00m\n",
      "    └── \u001b[01;34mhps_infer\u001b[00m\n",
      "        └── \u001b[01;34m1\u001b[00m\n",
      "\n",
      "3 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree -l $BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd5aa8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mhps_model\u001b[00m\n",
      "├── hps_train.json\n",
      "├── hps_train0_opt_sparse_1000.model\n",
      "├── \u001b[01;34mhps_train0_sparse_1000.model\u001b[00m\n",
      "│   ├── emb_vector\n",
      "│   └── key\n",
      "├── hps_train1_opt_sparse_1000.model\n",
      "├── \u001b[01;34mhps_train1_sparse_1000.model\u001b[00m\n",
      "│   ├── emb_vector\n",
      "│   └── key\n",
      "├── hps_train_dense_1000.model\n",
      "├── hps_train_label_1000\n",
      "├── hps_train_opt_dense_1000.model\n",
      "├── hps_train_pred_1000\n",
      "└── infer_test.csv\n",
      "\n",
      "2 directories, 12 files\n"
     ]
    }
   ],
   "source": [
    "!tree -l hps_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a44031",
   "metadata": {},
   "source": [
    "## Copy the model files to the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "523c9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/hps_demo\u001b[00m\n",
      "└── \u001b[01;34membedding\u001b[00m\n",
      "    └── \u001b[01;34mhps_infer\u001b[00m\n",
      "        └── \u001b[01;34m1\u001b[00m\n",
      "            ├── hps_train.json\n",
      "            ├── \u001b[01;34mhps_train0_sparse_1000.model\u001b[00m\n",
      "            │   ├── emb_vector\n",
      "            │   └── key\n",
      "            ├── \u001b[01;34mhps_train1_sparse_1000.model\u001b[00m\n",
      "            │   ├── emb_vector\n",
      "            │   └── key\n",
      "            └── hps_train_dense_1000.model\n",
      "\n",
      "5 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "!cp -r ./hps_model/hps_train0_sparse_1000.model /hps_demo/embedding/hps_infer/1\n",
    "!cp -r ./hps_model/hps_train1_sparse_1000.model /hps_demo/embedding/hps_infer/1\n",
    "!cp ./hps_model/hps_train_dense_1000.model /hps_demo/embedding/hps_infer/1\n",
    "!cp ./hps_model/hps_train.json /hps_demo/embedding/hps_infer/1\n",
    "!tree -l /hps_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed8417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1072ef81",
   "metadata": {},
   "source": [
    "## Triton model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4705cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify instance_group, config with 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efe9697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hps_demo/embedding/hps_infer/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_embedding_repo/config.pbtxt\n",
    "name: \"hps_infer\"\n",
    "backend: \"hps\"\n",
    "max_batch_size:1024,\n",
    "input [\n",
    "   {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "version_policy: {\n",
    "        specific:{versions: 1}\n",
    "},\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "# parameters [\n",
    "#   {\n",
    "#   key: \"config\"\n",
    "#   value: { string_value: \"/hps_demo/embedding/hps_infer/1/hps_train.json\" }\n",
    "#   },\n",
    "#   {\n",
    "#   key: \"gpucache\"\n",
    "#   value: { string_value: \"true\" }\n",
    "#   },\n",
    "#   {\n",
    "#   key: \"hit_rate_threshold\"\n",
    "#   value: { string_value: \"0.8\" }\n",
    "#   },\n",
    "#   {\n",
    "#   key: \"gpucacheper\"\n",
    "#   value: { string_value: \"0.5\" }\n",
    "#   },\n",
    "#   {\n",
    "#   key: \"label_dim\"\n",
    "#   value: { string_value: \"1\" }\n",
    "#   },\n",
    "#   {\n",
    "#   key: \"slots\"\n",
    "#   value: { string_value: \"28\" }\n",
    "#   }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520968f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe1296a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /hps_demo/embedding/hps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /hps_demo/embedding/hps.json\n",
    "{\n",
    "    \"supportlonglong\": true,\n",
    "    \"volatile_db\": {\n",
    "        \"type\": \"hash_map\",\n",
    "        \"user_name\": \"default\",\n",
    "        \"num_partitions\": 8,\n",
    "        \"max_get_batch_size\": 1024,\n",
    "        \"max_set_batch_size\": 1024,\n",
    "        \"overflow_policy\": \"evict_oldest\",\n",
    "        \"overflow_margin\": 1024,\n",
    "        \"overflow_resolution_target\": 0.8,\n",
    "        \"initial_cache_rate\": 1.0\n",
    "    },\n",
    "#     \"persistent_db\": {\n",
    "#         \"type\": \"disabled\"\n",
    "#     },\n",
    "    \"models\": [{\n",
    "        \"model\": \"hps_infer\",\n",
    "        \"sparse_files\": [\"/hps_demo/embedding/hps_infer/1/hps_train0_sparse_1000.model\", \"/hps_demo/embedding/hps_infer/1/hps_train1_sparse_1000.model\"],\n",
    "        \"dense_file\":\"/hps_demo/embedding/hps_infer/1/hps_train_dense_1000.model\",\n",
    "        \"network_file\":\"/hps_demo/embedding/hps_infer/1/hps_train.json\",\n",
    "        \"num_of_worker_buffer_in_pool\": 4,\n",
    "        # \"embedding_table_names\":[\"sparse_embedding1\",\"sparse_embedding2\"],\n",
    "        \"embedding_vecsize_per_table\":[16,32],\n",
    "        \"maxnum_catfeature_query_per_table_per_sample\":[2,2],\n",
    "        \"default_value_for_each_table\":[0.0,0.0],\n",
    "        \"deployed_device_list\":[0],\n",
    "        \"max_batch_size\":1024,\n",
    "        \"cache_refresh_percentage_per_iteration\":0.2,\n",
    "        \"hit_rate_threshold\":0.8,\n",
    "        \"gpucacheper\":0.5,\n",
    "        \"gpucache\":true,\n",
    "        \"maxnum_des_feature_per_sample\": 13,\n",
    "        \"slot_num\":28\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28847cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tritonserver --model-repository=/hps_demo/embedding/ --load-model=hps_infer --model-control-mode=explicit --backend-directory=/usr/local/hugectr/backends --backend-config=hps,ps=/hps_demo/embedding/hps.json\n",
    "# tritonserver --model-repository=/hps_infer/embedding/ --load-model=hps_wdl --model-control-mode=explicit --backend-directory=/usr/local/hugectr/backends --backend-config=hps,ps=/hps_infer/embedding/hps.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd0826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a4e382",
   "metadata": {},
   "source": [
    "## Confirm Triton shared library\n",
    "If it doesn't exist, it needs to be recompiled and copied to corresponding directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b966333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/hps_demo\u001b[00m\n",
      "└── \u001b[01;34membedding\u001b[00m\n",
      "    ├── hps.json\n",
      "    └── \u001b[01;34mhps_infer\u001b[00m\n",
      "        ├── \u001b[01;34m1\u001b[00m\n",
      "        │   ├── hps_train.json\n",
      "        │   ├── \u001b[01;34mhps_train0_sparse_1000.model\u001b[00m\n",
      "        │   │   ├── emb_vector\n",
      "        │   │   └── key\n",
      "        │   ├── \u001b[01;34mhps_train1_sparse_1000.model\u001b[00m\n",
      "        │   │   ├── emb_vector\n",
      "        │   │   └── key\n",
      "        │   └── hps_train_dense_1000.model\n",
      "        ├── config.pbtxt\n",
      "        └── infer_test.csv\n",
      "\n",
      "5 directories, 9 files\n"
     ]
    }
   ],
   "source": [
    "!tree -l /hps_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434e520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d514f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /usr/local/hugectr/backends/hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "565f7f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/usr/local/hugectr/backends\u001b[00m\n",
      "├── \u001b[01;34mhps\u001b[00m\n",
      "│   └── \u001b[01;32mlibtriton_hps.so\u001b[00m\n",
      "└── \u001b[01;34mhugectr\u001b[00m\n",
      "    └── \u001b[01;32mlibtriton_hugectr.so\u001b[00m\n",
      "\n",
      "2 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree -l /usr/local/hugectr/backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6726a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /workspace/merlin/hugectr_inference_backend/build/libtriton_hugectr.so /usr/local/hugectr/backends/hugectr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d7f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tritonserver --model-repository=/hps_demo/embedding/ --load-model=hps_infer \\\n",
    "    --model-control-mode=explicit \\\n",
    "    --backend-directory=/usr/local/hugectr/backends \\\n",
    "    --backend-config=hps,ps=/hps_demor/embedding/hps.json\n",
    "# !tritonserver --model-repository=/hps_demo/embedding/ --load-model=hps_infer --model-control-mode=explicit --backend-directory=/usr/local/hugectr/backends --backend-config=hps,ps=/hps_demo/embedding/hps.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b2110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfdaf5bd",
   "metadata": {},
   "source": [
    "## Preparing HPS inferencing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d43ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8196\n",
      "-rw-r--r-- 1 root root     747 Jun 27 07:47 _metadata.json\n",
      "-rw-r--r-- 1 root root 2094641 Jun 27 07:46 gen_0.parquet\n",
      "-rw-r--r-- 1 root root 2093496 Jun 27 07:46 gen_1.parquet\n",
      "-rw-r--r-- 1 root root 2094009 Jun 27 07:46 gen_2.parquet\n",
      "-rw-r--r-- 1 root root 2093936 Jun 27 07:46 gen_3.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./data_parquet/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2218ca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_col0</th>\n",
       "      <th>_col1</th>\n",
       "      <th>_col2</th>\n",
       "      <th>_col3</th>\n",
       "      <th>_col4</th>\n",
       "      <th>_col5</th>\n",
       "      <th>_col6</th>\n",
       "      <th>_col7</th>\n",
       "      <th>_col8</th>\n",
       "      <th>_col9</th>\n",
       "      <th>_col10</th>\n",
       "      <th>_col11</th>\n",
       "      <th>_col12</th>\n",
       "      <th>_col13</th>\n",
       "      <th>_col14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369659</td>\n",
       "      <td>0.562382</td>\n",
       "      <td>0.268092</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.425515</td>\n",
       "      <td>0.436015</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.969748</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>0.317950</td>\n",
       "      <td>0.050502</td>\n",
       "      <td>1</td>\n",
       "      <td>434</td>\n",
       "      <td>1026</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105705</td>\n",
       "      <td>0.476559</td>\n",
       "      <td>0.835602</td>\n",
       "      <td>0.103531</td>\n",
       "      <td>0.256015</td>\n",
       "      <td>0.835396</td>\n",
       "      <td>0.476131</td>\n",
       "      <td>0.923220</td>\n",
       "      <td>0.899870</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.691802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.818356</td>\n",
       "      <td>0.255720</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.023801</td>\n",
       "      <td>0.751817</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.261466</td>\n",
       "      <td>0.645097</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>0.348452</td>\n",
       "      <td>0.533557</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.201031</td>\n",
       "      <td>0.303372</td>\n",
       "      <td>0.502298</td>\n",
       "      <td>0.366995</td>\n",
       "      <td>0.754150</td>\n",
       "      <td>0.270130</td>\n",
       "      <td>0.811643</td>\n",
       "      <td>0.322071</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.338294</td>\n",
       "      <td>0.373525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923416</td>\n",
       "      <td>0.532531</td>\n",
       "      <td>0.791524</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.763071</td>\n",
       "      <td>0.649208</td>\n",
       "      <td>0.176048</td>\n",
       "      <td>0.956767</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.629382</td>\n",
       "      <td>0.667392</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _col0     _col1     _col2     _col3     _col4     _col5     _col6  \\\n",
       "0  0.369659  0.562382  0.268092  0.270976  0.425515  0.436015  0.794521   \n",
       "1  0.105705  0.476559  0.835602  0.103531  0.256015  0.835396  0.476131   \n",
       "2  0.818356  0.255720  0.896250  0.023801  0.751817  0.846724  0.261466   \n",
       "3  0.201031  0.303372  0.502298  0.366995  0.754150  0.270130  0.811643   \n",
       "4  0.923416  0.532531  0.791524  0.313665  0.763071  0.649208  0.176048   \n",
       "\n",
       "      _col7     _col8     _col9    _col10  _col11  _col12  _col13  _col14  \n",
       "0  0.969748  0.118850  0.317950  0.050502       1     434    1026      13  \n",
       "1  0.923220  0.899870  0.008765  0.691802       0       0      23       9  \n",
       "2  0.645097  0.173824  0.348452  0.533557       2      11     184       7  \n",
       "3  0.322071  0.037592  0.338294  0.373525       2       0      10       0  \n",
       "4  0.956767  0.219100  0.629382  0.667392      50       9       1      46  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"./data_parquet/val/gen_0.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd93ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'I1',\n",
       " 'I2',\n",
       " 'I3',\n",
       " 'I4',\n",
       " 'I5',\n",
       " 'I6',\n",
       " 'I7',\n",
       " 'I8',\n",
       " 'I9',\n",
       " 'I10',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reindex columns\n",
    "CATEGORICAL_COLUMNS=[\"C\" + str(x) for x in range(1, 5)]\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 11)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "cols = LABEL_COLUMNS + CONTINUOUS_COLUMNS + CATEGORICAL_COLUMNS\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236eace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369659</td>\n",
       "      <td>0.562382</td>\n",
       "      <td>0.268092</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.425515</td>\n",
       "      <td>0.436015</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.969748</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>0.317950</td>\n",
       "      <td>0.050502</td>\n",
       "      <td>1</td>\n",
       "      <td>434</td>\n",
       "      <td>1026</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105705</td>\n",
       "      <td>0.476559</td>\n",
       "      <td>0.835602</td>\n",
       "      <td>0.103531</td>\n",
       "      <td>0.256015</td>\n",
       "      <td>0.835396</td>\n",
       "      <td>0.476131</td>\n",
       "      <td>0.923220</td>\n",
       "      <td>0.899870</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.691802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.818356</td>\n",
       "      <td>0.255720</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.023801</td>\n",
       "      <td>0.751817</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.261466</td>\n",
       "      <td>0.645097</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>0.348452</td>\n",
       "      <td>0.533557</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.201031</td>\n",
       "      <td>0.303372</td>\n",
       "      <td>0.502298</td>\n",
       "      <td>0.366995</td>\n",
       "      <td>0.754150</td>\n",
       "      <td>0.270130</td>\n",
       "      <td>0.811643</td>\n",
       "      <td>0.322071</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.338294</td>\n",
       "      <td>0.373525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923416</td>\n",
       "      <td>0.532531</td>\n",
       "      <td>0.791524</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.763071</td>\n",
       "      <td>0.649208</td>\n",
       "      <td>0.176048</td>\n",
       "      <td>0.956767</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.629382</td>\n",
       "      <td>0.667392</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label        I1        I2        I3        I4        I5        I6  \\\n",
       "0  0.369659  0.562382  0.268092  0.270976  0.425515  0.436015  0.794521   \n",
       "1  0.105705  0.476559  0.835602  0.103531  0.256015  0.835396  0.476131   \n",
       "2  0.818356  0.255720  0.896250  0.023801  0.751817  0.846724  0.261466   \n",
       "3  0.201031  0.303372  0.502298  0.366995  0.754150  0.270130  0.811643   \n",
       "4  0.923416  0.532531  0.791524  0.313665  0.763071  0.649208  0.176048   \n",
       "\n",
       "         I7        I8        I9       I10  C1   C2    C3  C4  \n",
       "0  0.969748  0.118850  0.317950  0.050502   1  434  1026  13  \n",
       "1  0.923220  0.899870  0.008765  0.691802   0    0    23   9  \n",
       "2  0.645097  0.173824  0.348452  0.533557   2   11   184   7  \n",
       "3  0.322071  0.037592  0.338294  0.373525   2    0    10   0  \n",
       "4  0.956767  0.219100  0.629382  0.667392  50    9     1  46  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_axis(cols, axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ffb710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./hps_model/infer_test.csv', sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23153b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./hps_model/infer_test.csv /hps_demo/embedding/hps_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0a1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916bf401",
   "metadata": {},
   "source": [
    "## Triton inference server checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5cc129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:8000...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\n",
      "> GET /v2/health/ready HTTP/1.1\n",
      "> Host: localhost:8000\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Length: 0\n",
      "< Content-Type: text/plain\n",
      "< \n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18096891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client created.\n",
      "GET /v2/health/live, headers None\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tritonhttpclient\n",
    "\n",
    "try:\n",
    "    triton_client = tritonhttpclient.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "    print(\"client created.\")\n",
    "except Exception as e:\n",
    "    print(\"channel creation failed: \" + str(e))\n",
    "triton_client.is_server_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dcddaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/index, headers None\n",
      "\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '22'}>\n",
      "bytearray(b'[{\"name\":\"hps_infer\"}]')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'hps_infer'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_client.get_model_repository_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c70b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba6394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/index, headers None\n",
      "\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '46'}>\n",
      "bytearray(b'[{\"name\":\"wdl\",\"version\":\"1\",\"state\":\"READY\"}]')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'wdl', 'version': '1', 'state': 'READY'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_client.get_model_repository_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c807165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164f921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02bc8956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/models/wdl/load, headers None\n",
      "{}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n",
      "Loaded model 'wdl'\n"
     ]
    }
   ],
   "source": [
    "model_name = \"hps_infer\"\n",
    "triton_client.load_model(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da859c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ebc22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e68364",
   "metadata": {},
   "source": [
    "## HPS backend lookup test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b0190d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_col0</th>\n",
       "      <th>_col1</th>\n",
       "      <th>_col2</th>\n",
       "      <th>_col3</th>\n",
       "      <th>_col4</th>\n",
       "      <th>_col5</th>\n",
       "      <th>_col6</th>\n",
       "      <th>_col7</th>\n",
       "      <th>_col8</th>\n",
       "      <th>_col9</th>\n",
       "      <th>_col10</th>\n",
       "      <th>_col11</th>\n",
       "      <th>_col12</th>\n",
       "      <th>_col13</th>\n",
       "      <th>_col14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369659</td>\n",
       "      <td>0.562382</td>\n",
       "      <td>0.268092</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.425515</td>\n",
       "      <td>0.436015</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.969748</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>0.317950</td>\n",
       "      <td>0.050502</td>\n",
       "      <td>1</td>\n",
       "      <td>434</td>\n",
       "      <td>1026</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105705</td>\n",
       "      <td>0.476559</td>\n",
       "      <td>0.835602</td>\n",
       "      <td>0.103531</td>\n",
       "      <td>0.256015</td>\n",
       "      <td>0.835396</td>\n",
       "      <td>0.476131</td>\n",
       "      <td>0.923220</td>\n",
       "      <td>0.899870</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.691802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.818356</td>\n",
       "      <td>0.255720</td>\n",
       "      <td>0.896250</td>\n",
       "      <td>0.023801</td>\n",
       "      <td>0.751817</td>\n",
       "      <td>0.846724</td>\n",
       "      <td>0.261466</td>\n",
       "      <td>0.645097</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>0.348452</td>\n",
       "      <td>0.533557</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.201031</td>\n",
       "      <td>0.303372</td>\n",
       "      <td>0.502298</td>\n",
       "      <td>0.366995</td>\n",
       "      <td>0.754150</td>\n",
       "      <td>0.270130</td>\n",
       "      <td>0.811643</td>\n",
       "      <td>0.322071</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.338294</td>\n",
       "      <td>0.373525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923416</td>\n",
       "      <td>0.532531</td>\n",
       "      <td>0.791524</td>\n",
       "      <td>0.313665</td>\n",
       "      <td>0.763071</td>\n",
       "      <td>0.649208</td>\n",
       "      <td>0.176048</td>\n",
       "      <td>0.956767</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.629382</td>\n",
       "      <td>0.667392</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _col0     _col1     _col2     _col3     _col4     _col5     _col6  \\\n",
       "0  0.369659  0.562382  0.268092  0.270976  0.425515  0.436015  0.794521   \n",
       "1  0.105705  0.476559  0.835602  0.103531  0.256015  0.835396  0.476131   \n",
       "2  0.818356  0.255720  0.896250  0.023801  0.751817  0.846724  0.261466   \n",
       "3  0.201031  0.303372  0.502298  0.366995  0.754150  0.270130  0.811643   \n",
       "4  0.923416  0.532531  0.791524  0.313665  0.763071  0.649208  0.176048   \n",
       "\n",
       "      _col7     _col8     _col9    _col10  _col11  _col12  _col13  _col14  \n",
       "0  0.969748  0.118850  0.317950  0.050502       1     434    1026      13  \n",
       "1  0.923220  0.899870  0.008765  0.691802       0       0      23       9  \n",
       "2  0.645097  0.173824  0.348452  0.533557       2      11     184       7  \n",
       "3  0.322071  0.037592  0.338294  0.373525       2       0      10       0  \n",
       "4  0.956767  0.219100  0.629382  0.667392      50       9       1      46  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"./data_parquet/val/gen_0.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c2c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hugectr.inference import HPS, ParameterServerConfig, InferenceParams\n",
    "\n",
    "slot_size_array = [10000, 10000, 10000, 10000]\n",
    "key_offset = np.insert(np.cumsum(slot_size_array), 0, 0)[:-1]\n",
    "\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eddd0c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HCTR][04:26:55.573][WARNING][RK0][main]: default_value_for_each_table.size() is not equal to the number of embedding tables\n"
     ]
    }
   ],
   "source": [
    "# {\n",
    "#     \"supportlonglong\": true,\n",
    "#     \"volatile_db\": {\n",
    "#         \"type\": \"hash_map\",\n",
    "#         \"user_name\": \"default\",\n",
    "#         \"num_partitions\": 8,\n",
    "#         \"max_get_batch_size\": 1024,\n",
    "#         \"max_set_batch_size\": 1024,\n",
    "#         \"overflow_policy\": \"evict_oldest\",\n",
    "#         \"overflow_margin\": 1024,\n",
    "#         \"overflow_resolution_target\": 0.8,\n",
    "#         \"initial_cache_rate\": 1.0\n",
    "#     },\n",
    "#     \"persistent_db\": {\n",
    "#         \"type\": \"disabled\"\n",
    "#     },\n",
    "#     \"models\": [{\n",
    "#         \"model\": \"hps_infer\",\n",
    "#         \"sparse_files\": [\"/hps_demo/embedding/hps_infer/1/hps_train0_sparse_1000.model\", \"/hps_demo/embedding/hps_infer/1/hps_train1_sparse_1000.model\"],\n",
    "#         \"dense_file\":\"/hps_demo/embedding/hps_infer/1/hps_train_dense_1000.model\",\n",
    "#         \"network_file\":\"/hps_demo/embedding/hps_infer/1/hps_train.json\",\n",
    "#         \"num_of_worker_buffer_in_pool\": 4,\n",
    "#         # \"embedding_table_names\":[\"sparse_embedding1\",\"sparse_embedding2\"],\n",
    "#         \"embedding_vecsize_per_table\":[1,5],\n",
    "#         \"maxnum_catfeature_query_per_table_per_sample\":[2,4],\n",
    "#         \"default_value_for_each_table\":[0.0,0.0],\n",
    "#         \"deployed_device_list\":[0],\n",
    "#         \"max_batch_size\":1024,\n",
    "#         \"cache_refresh_percentage_per_iteration\":0.2,\n",
    "#         \"hit_rate_threshold\":0.8,\n",
    "#         \"gpucacheper\":0.5,\n",
    "#         \"gpucache\":true,\n",
    "#         \"maxnum_des_feature_per_sample\": 13,\n",
    "#         \"slot_num\":28\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "key: value \n",
    "\n",
    "# 1. Configure the HPS hyperparameters\n",
    "ps_config = ParameterServerConfig(\n",
    "           emb_table_name = {\"hps_infer\": [\"sparse_embedding1\", \"sparse_embedding2\"]},\n",
    "           embedding_vec_size = {\"hps_infer\": [16, 32]},\n",
    "           max_feature_num_per_sample_per_emb_table = {\"hps_infer\": [2, 2]},\n",
    "           inference_params_array = [\n",
    "              InferenceParams(\n",
    "                model_name = \"hps_infer\",\n",
    "                max_batchsize = batch_size,\n",
    "                hit_rate_threshold = 0.9,\n",
    "                dense_model_file = \"/hps_demo/embedding/hps_infer/1/hps_train_dense_1000.model\",\n",
    "                sparse_model_files = [\"/hps_demo/embedding/hps_infer/1/hps_train0_sparse_1000.model\", \"/hps_demo/embedding/hps_infer/1/hps_train1_sparse_1000.model\"],\n",
    "                deployed_devices = [0],\n",
    "                use_gpu_embedding_cache = True,\n",
    "                cache_size_percentage = 0.5,\n",
    "                i64_input_key = True)\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b616f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HCTR][04:26:57.320][INFO][RK0][main]: Creating ParallelHashMap CPU database backend...\n",
      "[HCTR][04:26:57.320][INFO][RK0][main]: Created parallel (16 partitions) blank database backend in local memory!\n",
      "[HCTR][04:26:57.320][INFO][RK0][main]: Volatile DB: initial cache rate = 1\n",
      "[HCTR][04:26:57.320][INFO][RK0][main]: Volatile DB: cache missed embeddings = 0\n",
      "[HCTR][04:26:57.324][INFO][RK0][main]: Table: hps_et.hps_infer.sparse_embedding1; cached 18502 / 18502 embeddings in volatile database (ParallelHashMap); load: 18403 / 18446744073709551615 (0.00%).\n",
      "[HCTR][04:26:57.328][INFO][RK0][main]: Table: hps_et.hps_infer.sparse_embedding2; cached 18471 / 18471 embeddings in volatile database (ParallelHashMap); load: 18432 / 18446744073709551615 (0.00%).\n",
      "[HCTR][04:26:57.328][DEBUG][RK0][main]: Real-time subscribers created!\n",
      "[HCTR][04:26:57.328][INFO][RK0][main]: Create embedding cache in device 0.\n",
      "[HCTR][04:26:57.329][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 0.500000\n",
      "[HCTR][04:26:57.329][INFO][RK0][main]: Configured cache hit rate threshold: 0.900000\n",
      "[HCTR][04:26:57.587][INFO][RK0][main]: Create inference session on device: 0\n",
      "[HCTR][04:26:57.587][INFO][RK0][main]: Model name: hps_infer\n",
      "[HCTR][04:26:57.587][INFO][RK0][main]: Number of embedding tables: 2\n",
      "[HCTR][04:26:57.587][INFO][RK0][main]: Use I64 input key: True\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize the HPS object\n",
    "hps = HPS(ps_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d76ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "056b1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_input_columns = df.columns[1:11]\n",
    "cat_input1_columns = df.columns[11:13]\n",
    "cat_input2_columns = df.columns[13:15]\n",
    "\n",
    "dense_input = df[dense_input_columns].loc[0:batch_size-1].to_numpy(dtype=np.float32)\n",
    "cat_input1 = (df[cat_input1_columns].loc[0:batch_size-1].to_numpy(dtype=np.int64) + key_offset[0:2]).reshape((batch_size, 2, 1))\n",
    "cat_input2 = (df[cat_input2_columns].loc[0:batch_size-1].to_numpy(dtype=np.int64) + key_offset[2:4]).reshape((batch_size, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c30837ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[21026],\n",
       "        [30013]],\n",
       "\n",
       "       [[20023],\n",
       "        [30009]],\n",
       "\n",
       "       [[20184],\n",
       "        [30007]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[20038],\n",
       "        [30128]],\n",
       "\n",
       "       [[20000],\n",
       "        [30006]],\n",
       "\n",
       "       [[22539],\n",
       "        [30002]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26c97951",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = hps.lookup(cat_input1.flatten(), \"hps_infer\", 0).reshape(batch_size, 2, 16)\n",
    "embedding2 = hps.lookup(cat_input2.flatten(), \"hps_infer\", 1).reshape(batch_size, 2, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7b9c343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.02091913, -0.0245843 ,  0.00519327, ...,  0.05002215,\n",
       "          0.0294596 , -0.00103364],\n",
       "        [-0.02237339, -0.04672453, -0.08426863, ..., -0.006162  ,\n",
       "          0.03486787,  0.0231818 ]],\n",
       "\n",
       "       [[ 0.00268956, -0.03547193, -0.02675142, ..., -0.00451016,\n",
       "          0.03903984,  0.02784371],\n",
       "        [-0.02455933,  0.00980662, -0.01644394, ...,  0.07740933,\n",
       "         -0.01624971, -0.0260106 ]],\n",
       "\n",
       "       [[ 0.06169097, -0.01005946,  0.05958775, ..., -0.0071731 ,\n",
       "         -0.04912148,  0.01603535],\n",
       "        [ 0.02991991, -0.05435334,  0.02359069, ...,  0.0072039 ,\n",
       "          0.04155782, -0.00181016]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.01374337, -0.02018151,  0.04546216, ..., -0.0113276 ,\n",
       "          0.03415666, -0.00190524],\n",
       "        [ 0.02849225,  0.03547915,  0.02032976, ...,  0.06046814,\n",
       "          0.04641226,  0.02678333]],\n",
       "\n",
       "       [[ 0.00122309, -0.01964738,  0.01284585, ...,  0.00782298,\n",
       "          0.0129297 ,  0.01203257],\n",
       "        [-0.02412293,  0.01057217,  0.00995403, ...,  0.00628727,\n",
       "         -0.01130908, -0.00149508]],\n",
       "\n",
       "       [[ 0.01309626,  0.04358894,  0.0650896 , ..., -0.01046022,\n",
       "          0.03659728, -0.01070743],\n",
       "        [ 0.01917225,  0.0046735 , -0.02395402, ..., -0.01185124,\n",
       "         -0.03427135, -0.00604474]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ba0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ffd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sess = ort.InferenceSession(\"hps_demo_without_embedding.onnx\")\n",
    "# res = sess.run(output_names=[sess.get_outputs()[0].name],\n",
    "#                input_feed={sess.get_inputs()[0].name: dense_input,\n",
    "#                sess.get_inputs()[1].name: embedding1,\n",
    "#                sess.get_inputs()[2].name: embedding2})\n",
    "# pred = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395fb105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246ecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875717a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf095276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a088e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "483fd7a2",
   "metadata": {},
   "source": [
    "## HPS backend model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b34ca3c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceServerException",
     "evalue": "Request for unknown model: 'hps_infer' is not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# inputs[2].set_data_from_numpy(row_ptrs)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m     httpclient\u001b[38;5;241m.\u001b[39mInferRequestedOutput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUTPUT0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m ]\n\u001b[0;32m---> 37\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget_response()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py:1372\u001b[0m, in \u001b[0;36mInferenceServerClient.infer\u001b[0;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, headers, query_params, request_compression_algorithm, response_compression_algorithm)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     request_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2/models/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/infer\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(quote(model_name))\n\u001b[1;32m   1368\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(request_uri\u001b[38;5;241m=\u001b[39mrequest_uri,\n\u001b[1;32m   1369\u001b[0m                       request_body\u001b[38;5;241m=\u001b[39mrequest_body,\n\u001b[1;32m   1370\u001b[0m                       headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1371\u001b[0m                       query_params\u001b[38;5;241m=\u001b[39mquery_params)\n\u001b[0;32m-> 1372\u001b[0m \u001b[43m_raise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m InferResult(response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py:64\u001b[0m, in \u001b[0;36m_raise_if_error\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     62\u001b[0m error \u001b[38;5;241m=\u001b[39m _get_error(response)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mInferenceServerException\u001b[0m: Request for unknown model: 'hps_infer' is not found"
     ]
    }
   ],
   "source": [
    "# %%writefile demo2predict.py\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.http  as httpclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "model_name = 'hps_infer'\n",
    "CATEGORICAL_COLUMNS=[\"C\" + str(x) for x in range(1, 5)]\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 11)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "emb_size_array = [10000, 10000, 10000, 10000]\n",
    "shift = np.insert(np.cumsum(emb_size_array), 0, 0)[:-1]\n",
    "test_df=pd.read_csv(\"./hps_model/infer_test.csv\",sep=',')\n",
    "\n",
    "\n",
    "\n",
    "# %%writefile $wdl_embedding_repo/config.pbtxt\n",
    "# name: \"hps_infer\"\n",
    "# backend: \"hps\"\n",
    "# max_batch_size:1024,\n",
    "input [\n",
    "  {\n",
    "    name: \"KEYS\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"NUMKEYS\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "# output [\n",
    "#   {\n",
    "#     name: \"OUTPUT0\"\n",
    "#     data_type: TYPE_FP32\n",
    "#     dims: [ -1 ]\n",
    "#   }\n",
    "# ]\n",
    "# version_policy: {\n",
    "#         specific:{versions: 1}\n",
    "# },\n",
    "# instance_group [\n",
    "#   {\n",
    "#     count: 1\n",
    "#     kind : KIND_GPU\n",
    "#     gpus:[0]\n",
    "#   }\n",
    "# ]\n",
    "\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    dense_features = np.array([list(test_df[CONTINUOUS_COLUMNS].values.flatten())],dtype='float32')\n",
    "    embedding_columns = np.array([list((test_df[CATEGORICAL_COLUMNS]+shift).values.flatten())],dtype='int64')\n",
    "    # row_ptrs = np.array([list(range(0,21))+list(range(0,261))],dtype='int32')\n",
    "    \n",
    "    inputs = [\n",
    "        httpclient.InferInput(\"DES\", dense_features.shape,\n",
    "                              np_to_triton_dtype(dense_features.dtype)),\n",
    "        httpclient.InferInput(\"CATCOLUMN\", embedding_columns.shape,\n",
    "                              np_to_triton_dtype(embedding_columns.dtype)),\n",
    "        # httpclient.InferInput(\"ROWINDEX\", row_ptrs.shape,\n",
    "        #                       np_to_triton_dtype(row_ptrs.dtype)),\n",
    "    ]\n",
    "\n",
    "    inputs[0].set_data_from_numpy(dense_features)\n",
    "    inputs[1].set_data_from_numpy(embedding_columns)\n",
    "    # inputs[2].set_data_from_numpy(row_ptrs)\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    response = client.infer(model_name,\n",
    "                            inputs,\n",
    "                            request_id=str(1),\n",
    "                            outputs=outputs)\n",
    "\n",
    "    result = response.get_response()\n",
    "    print(result)\n",
    "    print(\"Prediction Result:\")\n",
    "    print(response.as_numpy(\"OUTPUT0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc2f50e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./demo2predict.py\", line 36, in <module>\n",
      "    response = client.infer(model_name,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py\", line 1372, in infer\n",
      "    _raise_if_error(response)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py\", line 64, in _raise_if_error\n",
      "    raise error\n",
      "tritonclient.utils.InferenceServerException: Request for unknown model: 'hps_train' is not found\n"
     ]
    }
   ],
   "source": [
    "!python3 ./demo2predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74566742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514329ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9081bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096345f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5be4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f78187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
