{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1c22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hugectr\n",
    "from hugectr.tools import DataGeneratorParams, DataGenerator\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9490ab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HCTR][02:21:24.032][INFO][RK0][main]: Generate Parquet dataset\n",
      "[HCTR][02:21:24.032][INFO][RK0][main]: train data folder: ./data_parquet, eval data folder: ./data_parquet, slot_size_array: 10, 100, 1000, 10, 10, nnz array: 1, 1, 1, 1, 1, #files for train: 10, #files for eval: 4, #samples per file: 10000, Use power law distribution: 1, alpha of power law: 1.3\n",
      "[HCTR][02:21:24.032][INFO][RK0][main]: ./data_parquet exist\n",
      "[HCTR][02:21:24.032][INFO][RK0][main]: ./data_parquet exist\n",
      "[HCTR][02:21:24.032][INFO][RK0][main]: ./data_parquet/train exist\n",
      "[HCTR][02:21:24.032][INFO][RK0][main]: ./data_parquet/train/gen_0.parquet\n",
      "[HCTR][02:21:25.103][INFO][RK0][main]: ./data_parquet/train/gen_1.parquet\n",
      "[HCTR][02:21:25.142][INFO][RK0][main]: ./data_parquet/train/gen_2.parquet\n",
      "[HCTR][02:21:25.188][INFO][RK0][main]: ./data_parquet/train/gen_3.parquet\n",
      "[HCTR][02:21:25.230][INFO][RK0][main]: ./data_parquet/train/gen_4.parquet\n",
      "[HCTR][02:21:25.272][INFO][RK0][main]: ./data_parquet/train/gen_5.parquet\n",
      "[HCTR][02:21:25.316][INFO][RK0][main]: ./data_parquet/train/gen_6.parquet\n",
      "[HCTR][02:21:25.351][INFO][RK0][main]: ./data_parquet/train/gen_7.parquet\n",
      "[HCTR][02:21:25.383][INFO][RK0][main]: ./data_parquet/train/gen_8.parquet\n",
      "[HCTR][02:21:25.418][INFO][RK0][main]: ./data_parquet/train/gen_9.parquet\n",
      "[HCTR][02:21:25.452][INFO][RK0][main]: ./data_parquet/file_list.txt done!\n",
      "[HCTR][02:21:25.452][INFO][RK0][main]: ./data_parquet/val exist\n",
      "[HCTR][02:21:25.452][INFO][RK0][main]: ./data_parquet/val/gen_0.parquet\n",
      "[HCTR][02:21:25.488][INFO][RK0][main]: ./data_parquet/val/gen_1.parquet\n",
      "[HCTR][02:21:25.525][INFO][RK0][main]: ./data_parquet/val/gen_2.parquet\n",
      "[HCTR][02:21:25.562][INFO][RK0][main]: ./data_parquet/val/gen_3.parquet\n",
      "[HCTR][02:21:25.594][INFO][RK0][main]: ./data_parquet/file_list_test.txt done!\n"
     ]
    }
   ],
   "source": [
    "data_generator_params = DataGeneratorParams(\n",
    "  format = hugectr.DataReaderType_t.Parquet,\n",
    "  label_dim = 1,\n",
    "  dense_dim = 10,\n",
    "  num_slot = 5,\n",
    "  i64_input_key = True,\n",
    "  nnz_array = [1, 1, 1, 1, 1],\n",
    "  source = \"./data_parquet/file_list.txt\",\n",
    "  eval_source = \"./data_parquet/file_list_test.txt\",\n",
    "  slot_size_array = [10, 100, 1000, 10, 10],\n",
    "  check_type = hugectr.Check_t.Non,\n",
    "  dist_type = hugectr.Distribution_t.PowerLaw,\n",
    "  power_law_type = hugectr.PowerLaw_t.Short,\n",
    "  num_files = 10,\n",
    "  eval_num_files = 4,\n",
    "  num_samples_per_file = 10000)\n",
    "data_generator = DataGenerator(data_generator_params)\n",
    "data_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da4d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1021d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eaae5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9269da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "BASE_DIR = \"/hps_train\"\n",
    "train_path  = os.path.join(BASE_DIR, \"train\")\n",
    "val_path = os.path.join(BASE_DIR, \"val\")\n",
    "CUDA_VISIBLE_DEVICES = os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"0\")\n",
    "n_workers = len(CUDA_VISIBLE_DEVICES.split(\",\"))\n",
    "frac_size = 0.15\n",
    "allow_multi_gpu = False\n",
    "use_rmm_pool = False\n",
    "max_day = None  # (Optional) -- Limit the dataset to day 0-max_day for debugging\n",
    "\n",
    "if os.path.isdir(train_path):\n",
    "    shutil.rmtree(train_path)\n",
    "os.makedirs(train_path)\n",
    "\n",
    "if os.path.isdir(val_path):\n",
    "    shutil.rmtree(val_path)\n",
    "os.makedirs(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l $train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3dba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b0753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a236b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /hps_train/preprocess.py --data_path /hps_train/ --out_path /hps_train/ --freq_limit 6 --feature_cross_list C1_C2,C3_C4 --device_pool_frac 0.5  --devices \"0\" --num_io_threads 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c27a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda3faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a91e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50683416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd40aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e51a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = hugectr.CreateSolver(max_eval_batches = 2000,\n",
    "                              batchsize_eval = 1000,\n",
    "                              batchsize = 1000,\n",
    "                              lr = 0.001,\n",
    "                              vvgpu = [[2]],\n",
    "                              repeat_dataset = True,\n",
    "                              i64_input_key = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b289589",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = hugectr.DataReaderParams(data_reader_type = hugectr.DataReaderType_t.Parquet,\n",
    "                                  source = [\"./data_parquet/file_list.txt\"],\n",
    "                                  eval_source = \"./data_parquet/file_list_test.txt\",\n",
    "                                  check_type = hugectr.Check_t.Non,\n",
    "                                  slot_size_array = [10, 100, 1000, 10, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19ab4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = hugectr.CreateOptimizer(optimizer_type = hugectr.Optimizer_t.Adam,\n",
    "                                    update_type = hugectr.Update_t.Global,\n",
    "                                    beta1 = 0.9,\n",
    "                                    beta2 = 0.999,\n",
    "                                    epsilon = 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f95468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HugeCTR Version: 3.7\n",
      "====================================================Model Init=====================================================\n",
      "[HCTR][02:22:19.230][WARNING][RK0][main]: The model name is not specified when creating the solver.\n",
      "[HCTR][02:22:19.230][INFO][RK0][main]: Global seed is 62272102\n",
      "[HCTR][02:22:19.388][INFO][RK0][main]: Device to NUMA mapping:\n",
      "  GPU 2 ->  node 1\n",
      "[HCTR][02:22:21.670][WARNING][RK0][main]: Peer-to-peer access cannot be fully enabled.\n",
      "[HCTR][02:22:21.670][INFO][RK0][main]: Start all2all warmup\n",
      "[HCTR][02:22:21.672][INFO][RK0][main]: End all2all warmup\n",
      "[HCTR][02:22:21.673][INFO][RK0][main]: Using All-reduce algorithm: NCCL\n",
      "[HCTR][02:22:21.675][INFO][RK0][main]: Device 2: NVIDIA A100-SXM4-80GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "set_mempolicy: Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "model = hugectr.Model(solver, reader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adbd4ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HCTR][02:22:28.924][INFO][RK0][main]: num of DataReader workers: 1\n",
      "[HCTR][02:22:28.928][INFO][RK0][main]: Vocabulary size: 1130\n",
      "[HCTR][02:22:28.929][DEBUG][RK0][tid #139708910774016]: file_name_ ./data_parquet/val/gen_0.parquet file_total_rows_ 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "set_mempolicy: Operation not permitted\n",
      "set_mempolicy: Operation not permitted\n",
      "set_mempolicy: Operation not permitted\n",
      "set_mempolicy: Operation not permitted\n",
      "set_mempolicy: Operation not permitted\n",
      "set_mempolicy: Operation not permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HCTR][02:22:28.930][DEBUG][RK0][tid #139708919166720]: file_name_ ./data_parquet/train/gen_0.parquet file_total_rows_ 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HCTR][02:22:28.935][ERROR][RK0][tid #139708910774016]: Runtime error: Parquet worker : cat s-hot KeyType should be uint64/int64/int32/uint32\n",
      "\tError_t::WrongInput at read_a_batch(/workspace/merlin/hugectr/HugeCTR/include/data_readers/parquet_data_reader_worker.hpp:555)\n",
      "[HCTR][02:22:28.935][ERROR][RK0][tid #139708919166720]: Runtime error: Parquet worker : cat s-hot KeyType should be uint64/int64/int32/uint32\n",
      "\tError_t::WrongInput at read_a_batch(/workspace/merlin/hugectr/HugeCTR/include/data_readers/parquet_data_reader_worker.hpp:555)\n"
     ]
    }
   ],
   "source": [
    "model.add(hugectr.Input(label_dim = 1, label_name = \"label\",\n",
    "                        dense_dim = 10, dense_name = \"dense\",\n",
    "                        data_reader_sparse_param_array = \n",
    "                        [hugectr.DataReaderSparseParam(\"wide_data\", 1, True, 2),\n",
    "                        hugectr.DataReaderSparseParam(\"deep_data\", 2, False, 26)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca8a169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HCTR][02:22:32.879][INFO][RK0][main]: max_vocabulary_size_per_gpu_=699050\n",
      "[HCTR][02:22:32.881][INFO][RK0][main]: max_vocabulary_size_per_gpu_=737280\n"
     ]
    }
   ],
   "source": [
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash, \n",
    "                            workspace_size_per_gpu_in_mb = 8,\n",
    "                            embedding_vec_size = 1,\n",
    "                            combiner = \"sum\",\n",
    "                            sparse_embedding_name = \"sparse_embedding2\",\n",
    "                            bottom_name = \"wide_data\",\n",
    "                            optimizer = optimizer))\n",
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash, \n",
    "                            workspace_size_per_gpu_in_mb = 135,\n",
    "                            embedding_vec_size = 16,\n",
    "                            combiner = \"sum\",\n",
    "                            sparse_embedding_name = \"sparse_embedding1\",\n",
    "                            bottom_name = \"deep_data\",\n",
    "                            optimizer = optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "662f3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Reshape,\n",
    "                            bottom_names = [\"sparse_embedding1\"],\n",
    "                            top_names = [\"reshape1\"],\n",
    "                            leading_dim=416))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Reshape,\n",
    "                            bottom_names = [\"sparse_embedding2\"],\n",
    "                            top_names = [\"reshape2\"],\n",
    "                            leading_dim=2))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReduceSum,\n",
    "                            bottom_names = [\"reshape2\"],\n",
    "                            top_names = [\"wide_redn\"],\n",
    "                            axis = 1))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Concat,\n",
    "                            bottom_names = [\"reshape1\", \"dense\"],\n",
    "                            top_names = [\"concat1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"concat1\"],\n",
    "                            top_names = [\"fc1\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc1\"],\n",
    "                            top_names = [\"relu1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Dropout,\n",
    "                            bottom_names = [\"relu1\"],\n",
    "                            top_names = [\"dropout1\"],\n",
    "                            dropout_rate=0.5))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"dropout1\"],\n",
    "                            top_names = [\"fc2\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc2\"],\n",
    "                            top_names = [\"relu2\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Dropout,\n",
    "                            bottom_names = [\"relu2\"],\n",
    "                            top_names = [\"dropout2\"],\n",
    "                            dropout_rate=0.5))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"dropout2\"],\n",
    "                            top_names = [\"fc3\"],\n",
    "                            num_output=1))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Add,\n",
    "                            bottom_names = [\"fc3\", \"wide_redn\"],\n",
    "                            top_names = [\"add1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.BinaryCrossEntropyLoss,\n",
    "                            bottom_names = [\"add1\", \"label\"],\n",
    "                            top_names = [\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()\n",
    "model.summary()\n",
    "model.fit(max_iter = 2000, display = 1000, eval_interval = 2000, snapshot = 10000, snapshot_prefix = \"hps\")\n",
    "model.graph_to_json(graph_config_file = \"hps_train.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634763b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b57b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(hugectr.Input(label_dim = 1, label_name = \"label\",\n",
    "                        dense_dim = 10, dense_name = \"dense\",\n",
    "                        data_reader_sparse_param_array = \n",
    "                        [hugectr.DataReaderSparseParam(\"wide_data\", 1, True, 2),\n",
    "                        hugectr.DataReaderSparseParam(\"deep_data\", 2, False, 26)]))\n",
    "\n",
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash, \n",
    "                            workspace_size_per_gpu_in_mb = 8,\n",
    "                            embedding_vec_size = 1,\n",
    "                            combiner = \"sum\",\n",
    "                            sparse_embedding_name = \"sparse_embedding2\",\n",
    "                            bottom_name = \"wide_data\",\n",
    "                            optimizer = optimizer))\n",
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash, \n",
    "                            workspace_size_per_gpu_in_mb = 135,\n",
    "                            embedding_vec_size = 16,\n",
    "                            combiner = \"sum\",\n",
    "                            sparse_embedding_name = \"sparse_embedding1\",\n",
    "                            bottom_name = \"deep_data\",\n",
    "                            optimizer = optimizer))\n",
    "\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Reshape,\n",
    "                            bottom_names = [\"sparse_embedding1\"],\n",
    "                            top_names = [\"reshape1\"],\n",
    "                            leading_dim=416))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Reshape,\n",
    "                            bottom_names = [\"sparse_embedding2\"],\n",
    "                            top_names = [\"reshape2\"],\n",
    "                            leading_dim=2))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReduceSum,\n",
    "                            bottom_names = [\"reshape2\"],\n",
    "                            top_names = [\"wide_redn\"],\n",
    "                            axis = 1))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Concat,\n",
    "                            bottom_names = [\"reshape1\", \"dense\"],\n",
    "                            top_names = [\"concat1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"concat1\"],\n",
    "                            top_names = [\"fc1\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc1\"],\n",
    "                            top_names = [\"relu1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Dropout,\n",
    "                            bottom_names = [\"relu1\"],\n",
    "                            top_names = [\"dropout1\"],\n",
    "                            dropout_rate=0.5))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"dropout1\"],\n",
    "                            top_names = [\"fc2\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc2\"],\n",
    "                            top_names = [\"relu2\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Dropout,\n",
    "                            bottom_names = [\"relu2\"],\n",
    "                            top_names = [\"dropout2\"],\n",
    "                            dropout_rate=0.5))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"dropout2\"],\n",
    "                            top_names = [\"fc3\"],\n",
    "                            num_output=1))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Add,\n",
    "                            bottom_names = [\"fc3\", \"wide_redn\"],\n",
    "                            top_names = [\"add1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.BinaryCrossEntropyLoss,\n",
    "                            bottom_names = [\"add1\", \"label\"],\n",
    "                            top_names = [\"loss\"]))\n",
    "model.compile()\n",
    "model.summary()\n",
    "model.fit(max_iter = 21000, display = 1000, eval_interval = 4000, snapshot = 20000, snapshot_prefix = \"wdl\")\n",
    "model.graph_to_json(graph_config_file = \"wdl.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55aa875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3de9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(data_generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633064d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a193b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bb3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_params = DataGeneratorParams(\n",
    "  format = hugectr.DataReaderType_t.Raw,\n",
    "  label_dim = 1,\n",
    "  dense_dim = 13,\n",
    "  num_slot = 26,\n",
    "  i64_input_key = False,\n",
    "  source = \"./dcn_raw/file_list.txt\",\n",
    "  eval_source = \"./dcn_raw/file_list_test.txt\",\n",
    "  slot_size_array = [39884, 39043, 17289, 7420, 20263, 3, 7120, 1543, 39884, 39043, 17289, 7420, 20263, 3, 7120, 1543, 63, 63, 39884, 39043, 17289, 7420, 20263, 3, 7120,\n",
    "  1543],\n",
    "  check_type = hugectr.Check_t.Sum,\n",
    "  dist_type = hugectr.Distribution_t.PowerLaw,\n",
    "  power_law_type = hugectr.PowerLaw_t.Short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bfc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(data_generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdaa80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635051d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896bdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c9fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312abc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir etc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38017e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hugectr\n",
    "from hugectr.tools import DataGeneratorParams, DataGenerator\n",
    "\n",
    "data_generator_params = DataGeneratorParams(\n",
    "  format = hugectr.DataReaderType_t.Parquet,\n",
    "  label_dim = 1,\n",
    "  dense_dim = 10,\n",
    "  num_slot = 4,\n",
    "  i64_input_key = True,\n",
    "  nnz_array = [1, 1, 1, 1],\n",
    "  source = \"./data_parquet/file_list.txt\",\n",
    "  eval_source = \"./data_parquet/file_list_test.txt\",\n",
    "  slot_size_array = [10000, 10000, 10000, 10000],\n",
    "  check_type = hugectr.Check_t.Non,\n",
    "  dist_type = hugectr.Distribution_t.PowerLaw,\n",
    "  power_law_type = hugectr.PowerLaw_t.Short,\n",
    "  num_files = 16,\n",
    "  eval_num_files = 4,\n",
    "  num_samples_per_file = 40960)\n",
    "data_generator = DataGenerator(data_generator_params)\n",
    "data_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bd072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540dbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir etc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa756a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hugectr\n",
    "from hugectr.tools import DataGenerator, DataGeneratorParams\n",
    "from mpi4py import MPI\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=(\"Data Generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument(\"--num_files\", type=int, help=\"number of files in training data\", default = 8)\n",
    "parser.add_argument(\"--eval_num_files\", type=int, help=\"number of files in validation data\", default = 2)\n",
    "parser.add_argument('--num_samples_per_file', type=int, help=\"number of samples per file\", default=1000000)\n",
    "parser.add_argument('--dir_name', type=str, help=\"data directory name(Required)\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_generator_params = DataGeneratorParams(\n",
    "  format = hugectr.DataReaderType_t.Parquet,\n",
    "  label_dim = 1,\n",
    "  dense_dim = 13,\n",
    "  num_slot = 26,\n",
    "  num_files = args.num_files,\n",
    "  eval_num_files = args.eval_num_files,\n",
    "  i64_input_key = True,\n",
    "  num_samples_per_file = args.num_samples_per_file,\n",
    "  source = \"./etc_data/\" + args.dir_name + \"/file_list.txt\",\n",
    "  eval_source = \"./etc_data/\" + args.dir_name + \"/file_list_test.txt\",\n",
    "  slot_size_array = [12988, 7129, 8720, 5820, 15196, 4, 4914, 1020, 30, 14274, 10220, 15088, 10, 1518, 3672, 48, 4, 820, 15, 12817, 13908, 13447, 9447, 5867, 45, 33],\n",
    "  # for parquet, check_type doesn't make any difference\n",
    "  check_type = hugectr.Check_t.Non,\n",
    "  dist_type = hugectr.Distribution_t.PowerLaw,\n",
    "  power_law_type = hugectr.PowerLaw_t.Short)\n",
    "data_generator = DataGenerator(data_generator_params)\n",
    "data_generator.generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087712cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hugectr\n",
    "from hugectr.tools import DataGeneratorParams, DataGenerator\n",
    "\n",
    "data_generator_params = DataGeneratorParams(\n",
    "  format = hugectr.DataReaderType_t.Parquet,\n",
    "  label_dim = 2,\n",
    "  dense_dim = 10,\n",
    "  num_slot = 5,\n",
    "  i64_input_key = True,\n",
    "  nnz_array = [1, 1, 1, 1, 1],\n",
    "  source = \"./data_parquet/file_list.txt\",\n",
    "  eval_source = \"./data_parquet/file_list_test.txt\",\n",
    "  slot_size_array = [10, 100, 1000, 10, 10],\n",
    "  check_type = hugectr.Check_t.Non,\n",
    "  dist_type = hugectr.Distribution_t.PowerLaw,\n",
    "  power_law_type = hugectr.PowerLaw_t.Short,\n",
    "  num_files = 10,\n",
    "  eval_num_files = 4,\n",
    "  num_samples_per_file = 4000)\n",
    "\n",
    "# data_generator_params = DataGeneratorParams(\n",
    "#   format = hugectr.DataReaderType_t.Norm,\n",
    "#   label_dim = 1,\n",
    "#   dense_dim = 13,\n",
    "#   num_slot = 26,\n",
    "#   i64_input_key = False,\n",
    "#   source = \"./dcn_norm/file_list.txt\",\n",
    "#   eval_source = \"./dcn_norm/file_list_test.txt\",\n",
    "#   slot_size_array = [39884, 39043, 17289, 7420, 20263, 3, 7120, 1543, 39884, 39043, 17289, 7420, 20263, 3, 7120, 1543, 63, 63, 39884, 39043, 17289, 7420, 20263, 3, 7120,\n",
    "#   1543],\n",
    "#   check_type = hugectr.Check_t.Sum,\n",
    "#   dist_type = hugectr.Distribution_t.PowerLaw,\n",
    "#   power_law_type = hugectr.PowerLaw_t.Short)\n",
    "\n",
    "data_generator = DataGenerator(data_generator_params)\n",
    "data_generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"./data_parquet/train/gen_0.parquet\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4440984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f669b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c540b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hugectr\n",
    "from mpi4py import MPI\n",
    "solver = hugectr.CreateSolver(model_name = \"hps_demo\",\n",
    "                              max_eval_batches = 1,\n",
    "                              batchsize_eval = 1024,\n",
    "                              batchsize = 1024,\n",
    "                              lr = 0.001,\n",
    "                              vvgpu = [[0]],\n",
    "                              i64_input_key = True,\n",
    "                              repeat_dataset = True,\n",
    "                              use_cuda_graph = True)\n",
    "reader = hugectr.DataReaderParams(data_reader_type = hugectr.DataReaderType_t.Parquet,\n",
    "                                  source = [\"./data_parquet/file_list.txt\"],\n",
    "                                  eval_source = \"./data_parquet/file_list_test.txt\",\n",
    "                                  check_type = hugectr.Check_t.Non,\n",
    "                                  slot_size_array = [10000, 10000, 10000, 10000])\n",
    "optimizer = hugectr.CreateOptimizer(optimizer_type = hugectr.Optimizer_t.Adam)\n",
    "model = hugectr.Model(solver, reader, optimizer)\n",
    "model.add(hugectr.Input(label_dim = 1, label_name = \"label\",\n",
    "                        dense_dim = 10, dense_name = \"dense\",\n",
    "                        data_reader_sparse_param_array = \n",
    "                        [hugectr.DataReaderSparseParam(\"data1\", [1, 1], True, 2),\n",
    "                        hugectr.DataReaderSparseParam(\"data2\", [1, 1], True, 2)]))\n",
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash, \n",
    "                            workspace_size_per_gpu_in_mb = 4,\n",
    "                            embedding_vec_size = 16,\n",
    "                            combiner = \"sum\",\n",
    "                            sparse_embedding_name = \"sparse_embedding1\",\n",
    "                            bottom_name = \"data1\",\n",
    "                            optimizer = optimizer))\n",
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash, \n",
    "                            workspace_size_per_gpu_in_mb = 8,\n",
    "                            embedding_vec_size = 32,\n",
    "                            combiner = \"sum\",\n",
    "                            sparse_embedding_name = \"sparse_embedding2\",\n",
    "                            bottom_name = \"data2\",\n",
    "                            optimizer = optimizer))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Reshape,\n",
    "                            bottom_names = [\"sparse_embedding1\"],\n",
    "                            top_names = [\"reshape1\"],\n",
    "                            leading_dim=32))                            \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Reshape,\n",
    "                            bottom_names = [\"sparse_embedding2\"],\n",
    "                            top_names = [\"reshape2\"],\n",
    "                            leading_dim=64))                            \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Concat,\n",
    "                            bottom_names = [\"reshape1\", \"reshape2\", \"dense\"], top_names = [\"concat1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"concat1\"],\n",
    "                            top_names = [\"fc1\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc1\"],\n",
    "                            top_names = [\"relu1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu1\"],\n",
    "                            top_names = [\"fc2\"],\n",
    "                            num_output=1))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.BinaryCrossEntropyLoss,\n",
    "                            bottom_names = [\"fc2\", \"label\"],\n",
    "                            top_names = [\"loss\"]))\n",
    "model.compile()\n",
    "model.summary()\n",
    "model.graph_to_json(\"hps_demo.json\")\n",
    "model.fit(max_iter = 1100, display = 200, eval_interval = 1000, snapshot = 1000, snapshot_prefix = \"hps_demo\")\n",
    "model.export_predictions(\"hps_demo_pred_\" + str(1000), \"hps_demo_label_\" + str(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191bfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710ef9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
