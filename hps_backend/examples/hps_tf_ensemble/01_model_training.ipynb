{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01960ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c539d87-ea3c-4156-a548-37fc59f9d2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdcbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51ced60-fd3d-402e-bc96-fb7c7259a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict()\n",
    "\n",
    "args[\"gpu_num\"] = 4                               # the number of available GPUs\n",
    "args[\"iter_num\"] = 10                             # the number of training iteration\n",
    "args[\"slot_num\"] = 3                              # the number of feature fields in this embedding layer\n",
    "args[\"embed_vec_size\"] = 16                       # the dimension of embedding vectors\n",
    "args[\"global_batch_size\"] = 65536                 # the globally batchsize for all GPUs\n",
    "args[\"max_vocabulary_size\"] = 30000\n",
    "args[\"vocabulary_range_per_slot\"] = [[0,10000],[10000,20000],[20000,30000]]\n",
    "args[\"dense_model_path\"] = \"naive_dnn_dense.model\"\n",
    "args[\"embedding_table_path\"] = \"naive_dnn_sparse.model\"\n",
    "# args[\"saved_path\"] = \"naive_dnn_tf_saved_model\"\n",
    "args[\"np_key_type\"] = np.int64\n",
    "args[\"np_vector_type\"] = np.float32\n",
    "args[\"tf_key_type\"] = tf.int64\n",
    "args[\"tf_vector_type\"] = tf.float32\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, range(args[\"gpu_num\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e358cdc-ac7b-4ac7-8f67-502ace92a9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c20ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_samples(num_samples, vocabulary_range_per_slot, key_dtype = args[\"np_key_type\"]):\n",
    "    keys = list()\n",
    "    for vocab_range in vocabulary_range_per_slot:\n",
    "        keys_per_slot = np.random.randint(low=vocab_range[0], \n",
    "                                          high=vocab_range[1], \n",
    "                                          size=(num_samples, 1), \n",
    "                                          dtype=key_dtype)\n",
    "        keys.append(keys_per_slot)\n",
    "    keys = np.concatenate(np.array(keys), axis = 1)\n",
    "    labels = np.random.randint(low=0, high=2, size=(num_samples, 1))\n",
    "    return keys, labels\n",
    "\n",
    "# slice tensor into batches, 65536\n",
    "def tf_dataset(keys, labels, batchsize):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((keys, labels))\n",
    "    dataset = dataset.batch(batchsize, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e2c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64f6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel(tf.keras.models.Model):\n",
    "    def __init__(self,\n",
    "                 init_tensors,\n",
    "                 slot_num,\n",
    "                 embed_vec_size,\n",
    "                 **kwargs):\n",
    "        super(TrainModel, self).__init__(**kwargs)\n",
    "        \n",
    "        self.slot_num = slot_num\n",
    "        self.embed_vec_size = embed_vec_size\n",
    "        self.init_tensors = init_tensors\n",
    "        self.params = tf.Variable(initial_value=tf.concat(self.init_tensors, axis=0))\n",
    "        self.fc_1 = tf.keras.layers.Dense(units=256, activation=None,\n",
    "                                                 kernel_initializer=\"ones\",\n",
    "                                                 bias_initializer=\"zeros\",\n",
    "                                                 name='fc_1')\n",
    "        self.fc_2 = tf.keras.layers.Dense(units=128, activation=None,\n",
    "                                                 kernel_initializer=\"ones\",\n",
    "                                                 bias_initializer=\"zeros\",\n",
    "                                                 name='fc_2')\n",
    "        self.fc_3 = tf.keras.layers.Dense(units=1, activation=None,\n",
    "                                                 kernel_initializer=\"ones\",\n",
    "                                                 bias_initializer=\"zeros\",\n",
    "                                                 name='fc_3')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedding_vector = tf.nn.embedding_lookup(params=self.params, ids=inputs)\n",
    "        embedding_vector = tf.reshape(embedding_vector, shape=[-1, self.slot_num * self.embed_vec_size])\n",
    "        \n",
    "        logit = self.fc_3(self.fc_2(self.fc_1(embedding_vector)))\n",
    "        \n",
    "        return logit, embedding_vector\n",
    "\n",
    "    def summary(self):\n",
    "        inputs = tf.keras.Input(shape=(self.slot_num,), \n",
    "                                dtype=args[\"tf_key_type\"], \n",
    "                                name=\"input_dense\")\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=self.call(inputs))\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7e7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    init_tensors = np.ones(shape=[args[\"max_vocabulary_size\"], args[\"embed_vec_size\"]], dtype=args[\"np_vector_type\"])\n",
    "    \n",
    "    model = TrainModel(init_tensors, args[\"slot_num\"], args[\"embed_vec_size\"])\n",
    "    model.summary()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    \n",
    "    def _train_step(inputs, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logit, embedding_vector = model(inputs)\n",
    "            loss = loss_fn(labels, logit)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return logit, embedding_vector, loss\n",
    "\n",
    "    keys, labels = generate_random_samples(args[\"global_batch_size\"]  * args[\"iter_num\"], args[\"vocabulary_range_per_slot\"],  args[\"np_key_type\"])\n",
    "    dataset = tf_dataset(keys, labels, args[\"global_batch_size\"])\n",
    "    for i, (id_tensors, labels) in enumerate(dataset):\n",
    "        _, embedding_vector, loss = _train_step(id_tensors, labels)\n",
    "        print(\"-\"*20, \"Step {}, loss: {}\".format(i, loss),  \"-\"*20)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b651759a-bcf9-4a00-a580-936db6625df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(30000, 16) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_dense (InputLayer)    [(None, 3)]               0         \n",
      "                                                                 \n",
      " tf.compat.v1.nn.embedding_l  (None, 3, 16)            0         \n",
      " ookup (TFOpLambda)                                              \n",
      "                                                                 \n",
      " tf.reshape (TFOpLambda)     (None, 48)                0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 256)               12544     \n",
      "                                                                 \n",
      " fc_2 (Dense)                (None, 128)               32896     \n",
      "                                                                 \n",
      " fc_3 (Dense)                (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,569\n",
      "Trainable params: 45,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 08:39:04.335687: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 08:39:06.822696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14923 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "2022-08-04 08:39:06.824828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 28941 MB memory:  -> device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0\n",
      "2022-08-04 08:39:06.826844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 28941 MB memory:  -> device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0\n",
      "2022-08-04 08:39:06.828896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 28941 MB memory:  -> device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Step 0, loss: 785784.0 --------------------\n",
      "-------------------- Step 1, loss: 516876.71875 --------------------\n",
      "-------------------- Step 2, loss: 325915.84375 --------------------\n",
      "-------------------- Step 3, loss: 198665.296875 --------------------\n",
      "-------------------- Step 4, loss: 115924.0859375 --------------------\n",
      "-------------------- Step 5, loss: 64979.5078125 --------------------\n",
      "-------------------- Step 6, loss: 34690.1328125 --------------------\n",
      "-------------------- Step 7, loss: 17438.54296875 --------------------\n",
      "-------------------- Step 8, loss: 8121.5849609375 --------------------\n",
      "-------------------- Step 9, loss: 3425.77734375 --------------------\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(args)\n",
    "weights_list = trained_model.get_weights()\n",
    "embedding_weights = weights_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c99a56c-33e9-4ba8-aff6-57906a21ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_dense_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 48)]              0         \n",
      "                                                                 \n",
      " fc_1 (Dense)                (None, 256)               12544     \n",
      "                                                                 \n",
      " fc_2 (Dense)                (None, 128)               32896     \n",
      "                                                                 \n",
      " fc_3 (Dense)                (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,569\n",
      "Trainable params: 45,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: naive_dnn_dense.model/assets\n"
     ]
    }
   ],
   "source": [
    "dense_model = tf.keras.models.Model(trained_model.get_layer(\"fc_1\").input, \n",
    "                                    trained_model.get_layer(\"fc_3\").output, \n",
    "                                    name='tf_dense_model')\n",
    "dense_model.summary()\n",
    "dense_model.save(args[\"dense_model_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd23a83-77d5-4d69-ba19-81e95fc930b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2f92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f11337-e10d-4f06-addb-984a14c1d90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b189ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sparse_model(embeddings_weights, embedding_table_path, embedding_vec_size):\n",
    "    os.system(\"mkdir -p {}\".format(embedding_table_path))\n",
    "    \n",
    "    with open(\"{}/key\".format(embedding_table_path), 'wb') as key_file, \\\n",
    "        open(\"{}/emb_vector\".format(embedding_table_path), 'wb') as vec_file:\n",
    "        for key in range(embeddings_weights.shape[0]):\n",
    "            vec = embeddings_weights[key]\n",
    "            key_struct = struct.pack('q', key)\n",
    "            vec_struct = struct.pack(str(embedding_vec_size) + \"f\", *vec)\n",
    "            key_file.write(key_struct)\n",
    "            vec_file.write(vec_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "540ec43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_sparse_model(embedding_weights, args[\"embedding_table_path\"], args[\"embed_vec_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7724e046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "909f5b90-17c9-46ef-9860-de6bd81ae44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del dataset\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8fc44b-2dcc-4c8a-b314-0021c49fc0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b023c2-1e81-4f20-bbfe-b5d1b09ba217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb8844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d53b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a299bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71163a1-275e-44e4-9d5b-bb1c1a05f4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b999c-5023-4ad6-9334-b78ea07b5356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f6d30-82e1-4636-a244-24ba797c8914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005a62d-768f-4e1e-8011-c42e971cc0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bf5d6-cbbc-4163-a788-cfe94df9e9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab8afb-08d7-490c-b409-20922c099c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e2323-41e8-498b-b68f-952f14f24ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c49eb-8846-4a61-a7f9-294fb2e119ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d6e00-30a2-4f36-82ac-1314955ed5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
