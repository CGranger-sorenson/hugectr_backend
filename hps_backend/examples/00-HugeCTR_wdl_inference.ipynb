{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9bbee6-d033-4b6a-9822-504b5620a626",
   "metadata": {},
   "source": [
    "to deploy the end-to-end pipeline to generate prediction results for new data from trained TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454126c1-361d-4fb1-a827-183e59569416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/merlin/hugectr_inference_backend/hps_backend/examples\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e089f01b-11d8-44fb-b0ee-73e86590037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some data folder to store the model related files\n",
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/wdl_infer\"\n",
    "model_folder  = os.path.join(BASE_DIR, \"model\")\n",
    "wdl_model_repo= os.path.join(model_folder, \"wdl\")\n",
    "wdl_version =os.path.join(wdl_model_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(model_folder):\n",
    "    shutil.rmtree(model_folder)\n",
    "os.makedirs(model_folder)\n",
    "\n",
    "if os.path.isdir(wdl_model_repo):\n",
    "    shutil.rmtree(wdl_model_repo)\n",
    "os.makedirs(wdl_model_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f0326e-6df1-45d1-80fe-d795623164ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5840\n",
      "-rwxr-xr-x 1 root root    3590 Jun 29 07:55 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:55 wdl0_sparse_20000.model\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:55 wdl1_sparse_20000.model\n",
      "-rw-r--r-- 1 root root 5963780 Jun 29 07:55 wdl_dense_20000.model\n"
     ]
    }
   ],
   "source": [
    "!cp -r /workspace/data/wdl_models/wdl0_sparse_20000.model $wdl_version/\n",
    "!cp -r /workspace/data/wdl_models/wdl1_sparse_20000.model $wdl_version/\n",
    "!cp /workspace/data/wdl_models/wdl_dense_20000.model $wdl_version/\n",
    "!cp /workspace/data/wdl_models/wdl.json $wdl_version/\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57a8abb-ed8c-499d-8c5e-1d0c53ce8d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /wdl_infer/model/wdl/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_model_repo/config.pbtxt\n",
    "name: \"wdl\"\n",
    "backend: \"hugectr\"\n",
    "max_batch_size:64,\n",
    "input [\n",
    "   {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"ROWINDEX\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "\n",
    "parameters [\n",
    "  {\n",
    "  key: \"config\"\n",
    "  value: { string_value: \"/wdl_infer/model/wdl/1/wdl.json\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucache\"\n",
    "  value: { string_value: \"true\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"hit_rate_threshold\"\n",
    "  value: { string_value: \"0.8\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"gpucacheper\"\n",
    "  value: { string_value: \"0.5\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"label_dim\"\n",
    "  value: { string_value: \"1\" }\n",
    "  },\n",
    "  {\n",
    "  key: \"slots\"\n",
    "  value: { string_value: \"28\" }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad2f125-31ae-432d-a362-81bcfe6143d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /wdl_infer/model/ps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /wdl_infer/model/ps.json\n",
    "{\n",
    "    \"supportlonglong\":true,\n",
    "    \"models\":[\n",
    "        {\n",
    "            \"model\":\"wdl\",\n",
    "            \"sparse_files\":[\"/wdl_infer/model/wdl/1/wdl0_sparse_20000.model\", \"/wdl_infer/model/wdl/1/wdl1_sparse_20000.model\"],\n",
    "            \"dense_file\":\"/wdl_infer/model/wdl/1/wdl_dense_20000.model\",\n",
    "            \"network_file\":\"/wdl_infer/model/wdl/1/wdl.json\",\n",
    "            \"num_of_worker_buffer_in_pool\": 4,\n",
    "            \"num_of_refresher_buffer_in_pool\":1,\n",
    "            \"deployed_device_list\":[0],\n",
    "            \"max_batch_size\":64,\n",
    "            \"default_value_for_each_table\":[0.0,0.0],\n",
    "            \"hit_rate_threshold\":0.9,\n",
    "            \"gpucacheper\":0.5,\n",
    "            \"gpucache\":true,\n",
    "            \"cache_refresh_percentage_per_iteration\":0.2,\n",
    "            \"maxnum_des_feature_per_sample\": 13,\n",
    "            \"maxnum_catfeature_query_per_table_per_sample\" : [2,26],\n",
    "            \"embedding_vecsize_per_table\" : [1,15],\n",
    "            \"slot_num\":28\n",
    "        }\n",
    "    ]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ecccd0-4661-496d-bf85-f2cacc32419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 4 root root 4096 Jun 29 07:55 1\n",
      "-rw-r--r-- 1 root root  838 Jun 29 07:55 config.pbtxt\n",
      "total 5840\n",
      "-rwxr-xr-x 1 root root    3590 Jun 29 07:55 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:55 wdl0_sparse_20000.model\n",
      "drwxr-xr-x 2 root root    4096 Jun 29 07:55 wdl1_sparse_20000.model\n",
      "-rw-r--r-- 1 root root 5963780 Jun 29 07:55 wdl_dense_20000.model\n"
     ]
    }
   ],
   "source": [
    "!ls  -l $wdl_model_repo\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3152fa48-c279-4feb-a27f-3bd53feb2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0629 05:21:03.925945 10669 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f6f16000000' with size 268435456\n",
      "I0629 05:21:03.942581 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0629 05:21:03.942590 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 1 with size 67108864\n",
      "I0629 05:21:03.942595 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 2 with size 67108864\n",
      "I0629 05:21:03.942599 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 3 with size 67108864\n",
      "I0629 05:21:03.942603 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 4 with size 67108864\n",
      "I0629 05:21:03.942607 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 5 with size 67108864\n",
      "I0629 05:21:03.942611 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 6 with size 67108864\n",
      "I0629 05:21:03.942615 10669 cuda_memory_manager.cc:105] CUDA memory pool is created on device 7 with size 67108864\n",
      "I0629 05:21:04.911147 10669 model_repository_manager.cc:997] loading: wdl:1\n",
      "E0629 05:21:05.029320 10669 model_repository_manager.cc:1155] failed to load 'wdl' version 1: Not found: unable to load shared library: /usr/local/hugectr/backends/hugectr/libtriton_hugectr.so: undefined symbol: _ZN7HugeCTR15InferenceParamsC1ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEmfS8_RKSt6vectorIS6_SaIS6_EEibfbbfbbiifRKS9_IiSaIiEERKS9_IfSaIfEERKNS_22VolatileDatabaseParamsERKNS_24PersistentDatabaseParamsERKNS_18UpdateSourceParamsEiffRKS9_ImSaImEESY_SD_\n",
      "I0629 05:21:05.634420 10669 metrics.cc:651] Collecting metrics for GPU 0: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.634654 10669 metrics.cc:651] Collecting metrics for GPU 1: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.634669 10669 metrics.cc:651] Collecting metrics for GPU 2: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.634684 10669 metrics.cc:651] Collecting metrics for GPU 3: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.634697 10669 metrics.cc:651] Collecting metrics for GPU 4: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.634711 10669 metrics.cc:651] Collecting metrics for GPU 5: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.634726 10669 metrics.cc:651] Collecting metrics for GPU 6: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.634740 10669 metrics.cc:651] Collecting metrics for GPU 7: NVIDIA A100-SXM4-80GB\n",
      "I0629 05:21:05.639465 10669 tritonserver.cc:1962] \n",
      "+----------------------------------+------------------------------------------+\n",
      "| Option                           | Value                                    |\n",
      "+----------------------------------+------------------------------------------+\n",
      "| server_id                        | triton                                   |\n",
      "| server_version                   | 2.20.0                                   |\n",
      "| server_extensions                | classification sequence model_repository |\n",
      "|                                  |  model_repository(unload_dependents) sch |\n",
      "|                                  | edule_policy model_configuration system_ |\n",
      "|                                  | shared_memory cuda_shared_memory binary_ |\n",
      "|                                  | tensor_data statistics trace             |\n",
      "| model_repository_path[0]         | /wdl_infer/model/                        |\n",
      "| model_control_mode               | MODE_EXPLICIT                            |\n",
      "| startup_models_0                 | wdl                                      |\n",
      "| strict_model_config              | 1                                        |\n",
      "| rate_limit                       | OFF                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{1}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{2}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{3}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{4}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{5}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{6}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{7}    | 67108864                                 |\n",
      "| response_cache_byte_size         | 0                                        |\n",
      "| min_supported_compute_capability | 6.0                                      |\n",
      "| strict_readiness                 | 1                                        |\n",
      "| exit_timeout                     | 30                                       |\n",
      "+----------------------------------+------------------------------------------+\n",
      "\n",
      "I0629 05:21:05.639507 10669 server.cc:249] No server context available. Exiting immediately.\n",
      "error: creating server: Invalid argument - load failed for model 'wdl': version 1: Not found: unable to load shared library: /usr/local/hugectr/backends/hugectr/libtriton_hugectr.so: undefined symbol: _ZN7HugeCTR15InferenceParamsC1ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEmfS8_RKSt6vectorIS6_SaIS6_EEibfbbfbbiifRKS9_IiSaIiEERKS9_IfSaIfEERKNS_22VolatileDatabaseParamsERKNS_24PersistentDatabaseParamsERKNS_18UpdateSourceParamsEiffRKS9_ImSaImEESY_SD_;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!tritonserver --model-repository=/wdl_infer/model/ --load-model=wdl --model-control-mode=explicit --backend-directory=/usr/local/hugectr/backends --backend-config=hugectr,ps=/wdl_infer/model/ps.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7baed2-30e8-48d5-9fdc-161e5dfd5756",
   "metadata": {},
   "source": [
    "I0602 02:59:54.707962 549 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f46de000000' with size 268435456\n",
    "I0602 02:59:54.725485 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
    "I0602 02:59:54.725493 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 1 with size 67108864\n",
    "I0602 02:59:54.725501 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 2 with size 67108864\n",
    "I0602 02:59:54.725507 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 3 with size 67108864\n",
    "I0602 02:59:54.725512 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 4 with size 67108864\n",
    "I0602 02:59:54.725519 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 5 with size 67108864\n",
    "I0602 02:59:54.725524 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 6 with size 67108864\n",
    "I0602 02:59:54.725531 549 cuda_memory_manager.cc:105] CUDA memory pool is created on device 7 with size 67108864\n",
    "I0602 02:59:55.799304 549 model_repository_manager.cc:997] loading: wdl:1\n",
    "I0602 02:59:55.921125 549 hugectr.cc:1597] TRITONBACKEND_Initialize: hugectr\n",
    "I0602 02:59:55.921155 549 hugectr.cc:1604] Triton TRITONBACKEND API version: 1.8\n",
    "I0602 02:59:55.921161 549 hugectr.cc:1608] 'hugectr' TRITONBACKEND API version: 1.8\n",
    "I0602 02:59:55.921166 549 hugectr.cc:1631] The HugeCTR backend Repository location: /usr/local/hugectr/backends/hugectr\n",
    "I0602 02:59:55.921171 549 hugectr.cc:1640] The HugeCTR backend configuration: {\"cmdline\":{\"ps\":\"/wdl_infer/model/ps.json\"}}\n",
    "I0602 02:59:55.921188 549 hugectr.cc:344] *****Parsing Parameter Server Configuration from /wdl_infer/model/ps.json\n",
    "I0602 02:59:55.921241 549 hugectr.cc:365] Support 64-bit keys = 1\n",
    "I0602 02:59:55.921276 549 hugectr.cc:583] Model name = wdl\n",
    "I0602 02:59:55.921282 549 hugectr.cc:592] Model 'wdl' -> network file = /wdl_infer/model/wdl/1/wdl.json\n",
    "I0602 02:59:55.921290 549 hugectr.cc:599] Model 'wdl' -> max. batch size = 64\n",
    "I0602 02:59:55.921295 549 hugectr.cc:605] Model 'wdl' -> dense model file = /wdl_infer/model/wdl/1/wdl_dense_20000.model\n",
    "I0602 02:59:55.921302 549 hugectr.cc:611] Model 'wdl' -> sparse model files = [/wdl_infer/model/wdl/1/wdl0_sparse_20000.model, /wdl_infer/model/wdl/1/wdl1_sparse_20000.model]\n",
    "I0602 02:59:55.921309 549 hugectr.cc:622] Model 'wdl' -> use GPU embedding cache = 1\n",
    "I0602 02:59:55.921330 549 hugectr.cc:631] Model 'wdl' -> hit rate threshold = 0.9\n",
    "I0602 02:59:55.921336 549 hugectr.cc:639] Model 'wdl' -> per model GPU cache = 0.5\n",
    "[HCTR][02:59:55][WARNING][RK0][main]: default_value_for_each_table.size() is not equal to the number of embedding tables\n",
    "I0602 02:59:55.921374 549 hugectr.cc:655] Model 'wdl' -> num. pool worker buffers = 4\n",
    "I0602 02:59:55.921380 549 hugectr.cc:662] Model 'wdl' -> num. pool refresh buffers = 1\n",
    "I0602 02:59:55.921386 549 hugectr.cc:669] Model 'wdl' -> cache refresh rate per iteration = 0.2\n",
    "I0602 02:59:55.921393 549 hugectr.cc:678] Model 'wdl' -> deployed device list = [0]\n",
    "I0602 02:59:55.921400 549 hugectr.cc:686] Model 'wdl' -> default value for each table = [0, 0]\n",
    "I0602 02:59:55.921408 549 hugectr.cc:706] *****The HugeCTR Backend Parameter Server is creating... *****\n",
    "[HCTR][02:59:55][INFO][RK0][main]: default_emb_vec_value is not specified using default: 0\n",
    "[HCTR][02:59:55][INFO][RK0][main]: default_emb_vec_value is not specified using default: 0\n",
    "I0602 02:59:55.921561 549 hugectr.cc:714] ***** Parameter Server(Int64) is creating... *****\n",
    "[HCTR][02:59:55][INFO][RK0][main]: Creating ParallelHashMap CPU database backend...\n",
    "[HCTR][02:59:55][INFO][RK0][main]: Created parallel (16 partitions) blank database backend in local memory!\n",
    "[HCTR][02:59:55][INFO][RK0][main]: Volatile DB: initial cache rate = 1\n",
    "[HCTR][02:59:55][INFO][RK0][main]: Volatile DB: cache missed embeddings = 0\n",
    "[HCTR][02:59:55][DEBUG][RK0][main]: ParallelHashMap backend. Table: hps_et.wdl.sparse_embedding2. Inserted 268619 / 268619 pairs.\n",
    "[HCTR][02:59:55][INFO][RK0][main]: Table: hps_et.wdl.sparse_embedding2; cached 268619 / 268619 embeddings in volatile database (ParallelHashMap); load: 268619 / 18446744073709551615 (0.00%).\n",
    "[HCTR][02:59:56][DEBUG][RK0][main]: ParallelHashMap backend. Table: hps_et.wdl.sparse_embedding1. Inserted 1869965 / 1869965 pairs.\n",
    "[HCTR][02:59:56][INFO][RK0][main]: Table: hps_et.wdl.sparse_embedding1; cached 1869965 / 1869965 embeddings in volatile database (ParallelHashMap); load: 1869965 / 18446744073709551615 (0.00%).\n",
    "[HCTR][02:59:56][DEBUG][RK0][main]: Real-time subscribers created!\n",
    "[HCTR][02:59:56][INFO][RK0][main]: Create embedding cache in device 0.\n",
    "[HCTR][02:59:56][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 0.500000\n",
    "[HCTR][02:59:56][INFO][RK0][main]: Configured cache hit rate threshold: 0.900000\n",
    "I0602 02:59:56.205984 549 hugectr.cc:725] *****The HugeCTR Backend Backend created the Parameter Server successfully! *****\n",
    "I0602 02:59:56.206050 549 hugectr.cc:1703] TRITONBACKEND_ModelInitialize: wdl (version 1)\n",
    "I0602 02:59:56.206056 549 hugectr.cc:1716] Repository location: /wdl_infer/model/wdl\n",
    "I0602 02:59:56.206062 549 hugectr.cc:1731] backend configuration in mode: {\"cmdline\":{\"ps\":\"/wdl_infer/model/ps.json\"}}\n",
    "I0602 02:59:56.207056 549 hugectr.cc:974] Verifying model configuration: {\n",
    "    \"name\": \"wdl\",\n",
    "    \"platform\": \"\",\n",
    "    \"backend\": \"hugectr\",\n",
    "    \"version_policy\": {\n",
    "        \"latest\": {\n",
    "            \"num_versions\": 1\n",
    "        }\n",
    "    },\n",
    "    \"max_batch_size\": 64,\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"name\": \"DES\",\n",
    "            \"data_type\": \"TYPE_FP32\",\n",
    "            \"format\": \"FORMAT_NONE\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"is_shape_tensor\": false,\n",
    "            \"allow_ragged_batch\": false,\n",
    "            \"optional\": false\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CATCOLUMN\",\n",
    "            \"data_type\": \"TYPE_INT64\",\n",
    "            \"format\": \"FORMAT_NONE\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"is_shape_tensor\": false,\n",
    "            \"allow_ragged_batch\": false,\n",
    "            \"optional\": false\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ROWINDEX\",\n",
    "            \"data_type\": \"TYPE_INT32\",\n",
    "            \"format\": \"FORMAT_NONE\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"is_shape_tensor\": false,\n",
    "            \"allow_ragged_batch\": false,\n",
    "            \"optional\": false\n",
    "        }\n",
    "    ],\n",
    "    \"output\": [\n",
    "        {\n",
    "            \"name\": \"OUTPUT0\",\n",
    "            \"data_type\": \"TYPE_FP32\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"label_filename\": \"\",\n",
    "            \"is_shape_tensor\": false\n",
    "        }\n",
    "    ],\n",
    "    \"batch_input\": [],\n",
    "    \"batch_output\": [],\n",
    "    \"optimization\": {\n",
    "        \"priority\": \"PRIORITY_DEFAULT\",\n",
    "        \"input_pinned_memory\": {\n",
    "            \"enable\": true\n",
    "        },\n",
    "        \"output_pinned_memory\": {\n",
    "            \"enable\": true\n",
    "        },\n",
    "        \"gather_kernel_buffer_threshold\": 0,\n",
    "        \"eager_batching\": false\n",
    "    },\n",
    "    \"instance_group\": [\n",
    "        {\n",
    "            \"name\": \"wdl_0\",\n",
    "            \"kind\": \"KIND_GPU\",\n",
    "            \"count\": 1,\n",
    "            \"gpus\": [\n",
    "                0\n",
    "            ],\n",
    "            \"secondary_devices\": [],\n",
    "            \"profile\": [],\n",
    "            \"passive\": false,\n",
    "            \"host_policy\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"default_model_filename\": \"\",\n",
    "    \"cc_model_filenames\": {},\n",
    "    \"metric_tags\": {},\n",
    "    \"parameters\": {\n",
    "        \"max_nnz\": {\n",
    "            \"string_value\": \"2\"\n",
    "        },\n",
    "        \"embedding_vector_size\": {\n",
    "            \"string_value\": \"128\"\n",
    "        },\n",
    "        \"gpucacheper\": {\n",
    "            \"string_value\": \"0.5\"\n",
    "        },\n",
    "        \"des_feature_num\": {\n",
    "            \"string_value\": \"13\"\n",
    "        },\n",
    "        \"hit_rate_threshold\": {\n",
    "            \"string_value\": \"0.8\"\n",
    "        },\n",
    "        \"gpucache\": {\n",
    "            \"string_value\": \"true\"\n",
    "        },\n",
    "        \"embeddingkey_long_type\": {\n",
    "            \"string_value\": \"true\"\n",
    "        },\n",
    "        \"slots\": {\n",
    "            \"string_value\": \"28\"\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"string_value\": \"/wdl_infer/model/wdl/1/wdl.json\"\n",
    "        },\n",
    "        \"cat_feature_num\": {\n",
    "            \"string_value\": \"28\"\n",
    "        },\n",
    "        \"label_dim\": {\n",
    "            \"string_value\": \"1\"\n",
    "        }\n",
    "    },\n",
    "    \"model_warmup\": []\n",
    "}\n",
    "I0602 02:59:56.207229 549 hugectr.cc:1060] The model configuration: {\n",
    "    \"name\": \"wdl\",\n",
    "    \"platform\": \"\",\n",
    "    \"backend\": \"hugectr\",\n",
    "    \"version_policy\": {\n",
    "        \"latest\": {\n",
    "            \"num_versions\": 1\n",
    "        }\n",
    "    },\n",
    "    \"max_batch_size\": 64,\n",
    "    \"input\": [\n",
    "        {\n",
    "            \"name\": \"DES\",\n",
    "            \"data_type\": \"TYPE_FP32\",\n",
    "            \"format\": \"FORMAT_NONE\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"is_shape_tensor\": false,\n",
    "            \"allow_ragged_batch\": false,\n",
    "            \"optional\": false\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CATCOLUMN\",\n",
    "            \"data_type\": \"TYPE_INT64\",\n",
    "            \"format\": \"FORMAT_NONE\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"is_shape_tensor\": false,\n",
    "            \"allow_ragged_batch\": false,\n",
    "            \"optional\": false\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ROWINDEX\",\n",
    "            \"data_type\": \"TYPE_INT32\",\n",
    "            \"format\": \"FORMAT_NONE\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"is_shape_tensor\": false,\n",
    "            \"allow_ragged_batch\": false,\n",
    "            \"optional\": false\n",
    "        }\n",
    "    ],\n",
    "    \"output\": [\n",
    "        {\n",
    "            \"name\": \"OUTPUT0\",\n",
    "            \"data_type\": \"TYPE_FP32\",\n",
    "            \"dims\": [\n",
    "                -1\n",
    "            ],\n",
    "            \"label_filename\": \"\",\n",
    "            \"is_shape_tensor\": false\n",
    "        }\n",
    "    ],\n",
    "    \"batch_input\": [],\n",
    "    \"batch_output\": [],\n",
    "    \"optimization\": {\n",
    "        \"priority\": \"PRIORITY_DEFAULT\",\n",
    "        \"input_pinned_memory\": {\n",
    "            \"enable\": true\n",
    "        },\n",
    "        \"output_pinned_memory\": {\n",
    "            \"enable\": true\n",
    "        },\n",
    "        \"gather_kernel_buffer_threshold\": 0,\n",
    "        \"eager_batching\": false\n",
    "    },\n",
    "    \"instance_group\": [\n",
    "        {\n",
    "            \"name\": \"wdl_0\",\n",
    "            \"kind\": \"KIND_GPU\",\n",
    "            \"count\": 1,\n",
    "            \"gpus\": [\n",
    "                0\n",
    "            ],\n",
    "            \"secondary_devices\": [],\n",
    "            \"profile\": [],\n",
    "            \"passive\": false,\n",
    "            \"host_policy\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"default_model_filename\": \"\",\n",
    "    \"cc_model_filenames\": {},\n",
    "    \"metric_tags\": {},\n",
    "    \"parameters\": {\n",
    "        \"max_nnz\": {\n",
    "            \"string_value\": \"2\"\n",
    "        },\n",
    "        \"embedding_vector_size\": {\n",
    "            \"string_value\": \"128\"\n",
    "        },\n",
    "        \"gpucacheper\": {\n",
    "            \"string_value\": \"0.5\"\n",
    "        },\n",
    "        \"des_feature_num\": {\n",
    "            \"string_value\": \"13\"\n",
    "        },\n",
    "        \"hit_rate_threshold\": {\n",
    "            \"string_value\": \"0.8\"\n",
    "        },\n",
    "        \"gpucache\": {\n",
    "            \"string_value\": \"true\"\n",
    "        },\n",
    "        \"embeddingkey_long_type\": {\n",
    "            \"string_value\": \"true\"\n",
    "        },\n",
    "        \"slots\": {\n",
    "            \"string_value\": \"28\"\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"string_value\": \"/wdl_infer/model/wdl/1/wdl.json\"\n",
    "        },\n",
    "        \"cat_feature_num\": {\n",
    "            \"string_value\": \"28\"\n",
    "        },\n",
    "        \"label_dim\": {\n",
    "            \"string_value\": \"1\"\n",
    "        }\n",
    "    },\n",
    "    \"model_warmup\": []\n",
    "}\n",
    "I0602 02:59:56.207347 549 hugectr.cc:1105] slots set = 28\n",
    "I0602 02:59:56.207354 549 hugectr.cc:1111] desene number = 13\n",
    "I0602 02:59:56.207360 549 hugectr.cc:1117] cat_feature number = 28\n",
    "I0602 02:59:56.207366 549 hugectr.cc:1129] embedding size = 128\n",
    "I0602 02:59:56.207372 549 hugectr.cc:1135] maxnnz = 2\n",
    "I0602 02:59:56.207378 549 hugectr.cc:1153] HugeCTR model config path = /wdl_infer/model/wdl/1/wdl.json\n",
    "I0602 02:59:56.207386 549 hugectr.cc:1176] support gpu cache = 1\n",
    "I0602 02:59:56.207403 549 hugectr.cc:1199] gpu cache per = 0.5\n",
    "I0602 02:59:56.207409 549 hugectr.cc:1216] hit-rate threshold = 0.8\n",
    "I0602 02:59:56.207415 549 hugectr.cc:1232] Label dim = 1\n",
    "I0602 02:59:56.207421 549 hugectr.cc:1238] support 64-bit embedding key = 1\n",
    "I0602 02:59:56.207426 549 hugectr.cc:1252] Model_Inference_Para.max_batchsize: 64\n",
    "I0602 02:59:56.207432 549 hugectr.cc:1256] max_batch_size in model config.pbtxt is 64\n",
    "I0602 02:59:56.207439 549 hugectr.cc:1326] ******Creating Embedding Cache for model wdl in device 0\n",
    "I0602 02:59:56.207445 549 hugectr.cc:1353] ******Creating Embedding Cache for model wdl successfully\n",
    "I0602 02:59:56.215901 549 hugectr.cc:1851] TRITONBACKEND_ModelInstanceInitialize: wdl_0 (device 0)\n",
    "I0602 02:59:56.215912 549 hugectr.cc:1495] Triton Model Instance Initialization on device 0\n",
    "I0602 02:59:56.256847 549 hugectr.cc:1505] Dense Feature buffer allocation: \n",
    "I0602 02:59:56.266345 549 hugectr.cc:1512] Categorical Feature buffer allocation: \n",
    "I0602 02:59:56.266456 549 hugectr.cc:1530] Categorical Row Index buffer allocation: \n",
    "I0602 02:59:56.266491 549 hugectr.cc:1540] Predict result buffer allocation: \n",
    "I0602 02:59:56.266524 549 hugectr.cc:1864] ******Loading HugeCTR Model******\n",
    "I0602 02:59:56.266531 549 hugectr.cc:1558] The model origin json configuration file path is: /wdl_infer/model/wdl/1/wdl.json\n",
    "[HCTR][02:59:56][INFO][RK0][main]: Global seed is 3783377676\n",
    "[HCTR][02:59:57][WARNING][RK0][main]: Peer-to-peer access cannot be fully enabled.\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Start all2all warmup\n",
    "[HCTR][02:59:57][INFO][RK0][main]: End all2all warmup\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Create inference session on device: 0\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Model name: wdl\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Use mixed precision: False\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Use cuda graph: True\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Max batchsize: 64\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Use I64 input key: True\n",
    "[HCTR][02:59:57][INFO][RK0][main]: start create embedding for inference\n",
    "[HCTR][02:59:57][INFO][RK0][main]: sparse_input name wide_data\n",
    "[HCTR][02:59:57][INFO][RK0][main]: sparse_input name deep_data\n",
    "[HCTR][02:59:57][INFO][RK0][main]: create embedding for inference success\n",
    "[HCTR][02:59:57][INFO][RK0][main]: Inference stage skip BinaryCrossEntropyLoss layer, replaced by Sigmoid layer\n",
    "I0602 02:59:58.134157 549 hugectr.cc:1565] ******Loading HugeCTR model successfully\n",
    "I0602 02:59:58.134444 549 model_repository_manager.cc:1152] successfully loaded 'wdl' version 1\n",
    "I0602 02:59:58.134605 549 server.cc:524] \n",
    "+------------------+------+\n",
    "| Repository Agent | Path |\n",
    "+------------------+------+\n",
    "+------------------+------+\n",
    "\n",
    "I0602 02:59:58.136089 549 server.cc:551] \n",
    "+---------+----------------------------------------------------------+-----------------------------------------------+\n",
    "| Backend | Path                                                     | Config                                        |\n",
    "+---------+----------------------------------------------------------+-----------------------------------------------+\n",
    "| hugectr | /usr/local/hugectr/backends/hugectr/libtriton_hugectr.so | {\"cmdline\":{\"ps\":\"/wdl_infer/model/ps.json\"}} |\n",
    "+---------+----------------------------------------------------------+-----------------------------------------------+\n",
    "\n",
    "I0602 02:59:58.136182 549 server.cc:594] \n",
    "+-------+---------+--------+\n",
    "| Model | Version | Status |\n",
    "+-------+---------+--------+\n",
    "| wdl   | 1       | READY  |\n",
    "+-------+---------+--------+\n",
    "\n",
    "I0602 02:59:58.310170 549 metrics.cc:651] Collecting metrics for GPU 0: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.310214 549 metrics.cc:651] Collecting metrics for GPU 1: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.310224 549 metrics.cc:651] Collecting metrics for GPU 2: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.310234 549 metrics.cc:651] Collecting metrics for GPU 3: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.310243 549 metrics.cc:651] Collecting metrics for GPU 4: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.310253 549 metrics.cc:651] Collecting metrics for GPU 5: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.310262 549 metrics.cc:651] Collecting metrics for GPU 6: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.310271 549 metrics.cc:651] Collecting metrics for GPU 7: NVIDIA A100-SXM4-80GB\n",
    "I0602 02:59:58.315118 549 tritonserver.cc:1962] \n",
    "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| Option                           | Value                                                                                                                                                                                  |\n",
    "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "| server_id                        | triton                                                                                                                                                                                 |\n",
    "| server_version                   | 2.20.0                                                                                                                                                                                 |\n",
    "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics |\n",
    "|                                  |  trace                                                                                                                                                                                 |\n",
    "| model_repository_path[0]         | /wdl_infer/model/                                                                                                                                                                      |\n",
    "| model_control_mode               | MODE_EXPLICIT                                                                                                                                                                          |\n",
    "| startup_models_0                 | wdl                                                                                                                                                                                    |\n",
    "| strict_model_config              | 1                                                                                                                                                                                      |\n",
    "| rate_limit                       | OFF                                                                                                                                                                                    |\n",
    "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                              |\n",
    "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                               |\n",
    "| cuda_memory_pool_byte_size{1}    | 67108864                                                                                                                                                                               |\n",
    "| cuda_memory_pool_byte_size{2}    | 67108864                                                                                                                                                                               |\n",
    "| cuda_memory_pool_byte_size{3}    | 67108864                                                                                                                                                                               |\n",
    "| cuda_memory_pool_byte_size{4}    | 67108864                                                                                                                                                                               |\n",
    "| cuda_memory_pool_byte_size{5}    | 67108864                                                                                                                                                                               |\n",
    "| cuda_memory_pool_byte_size{6}    | 67108864                                                                                                                                                                               |\n",
    "| cuda_memory_pool_byte_size{7}    | 67108864                                                                                                                                                                               |\n",
    "| response_cache_byte_size         | 0                                                                                                                                                                                      |\n",
    "| min_supported_compute_capability | 6.0                                                                                                                                                                                    |\n",
    "| strict_readiness                 | 1                                                                                                                                                                                      |\n",
    "| exit_timeout                     | 30                                                                                                                                                                                     |\n",
    "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
    "\n",
    "I0602 02:59:58.317667 549 grpc_server.cc:4421] Started GRPCInferenceService at 0.0.0.0:8001\n",
    "I0602 02:59:58.317944 549 http_server.cc:3113] Started HTTPService at 0.0.0.0:8000\n",
    "I0602 02:59:58.359119 549 http_server.cc:178] Started Metrics Service at 0.0.0.0:8002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb35dba0-db32-40c3-832a-ded993ee0c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8181f7e-cd7f-42ee-9ca5-08500c2df379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:8003...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 8003 (#0)\n",
      "> GET /v2/health/ready HTTP/1.1\n",
      "> Host: localhost:8003\n",
      "> User-Agent: curl/7.68.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 404 Not Found\n",
      "< Server: TornadoServer/6.1\n",
      "< Content-Type: text/html\n",
      "< Date: Thu, 02 Jun 2022 03:03:01 GMT\n",
      "< X-Content-Type-Options: nosniff\n",
      "< Content-Security-Policy: frame-ancestors 'self'; report-uri /api/security/csp-report\n",
      "< Content-Length: 2957\n",
      "< Set-Cookie: _xsrf=2|044a8628|2228373cfd3765ef4f764a5af0ce3e0e|1654138981; expires=Sat, 02 Jul 2022 03:03:01 GMT; Path=/\n",
      "< \n",
      "<!DOCTYPE HTML>\n",
      "<html>\n",
      "\n",
      "<head>\n",
      "\n",
      "    <meta charset=\"utf-8\">\n",
      "\n",
      "    <title>Jupyter Server</title>\n",
      "    <link id=\"favicon\" rel=\"shortcut icon\" type=\"image/x-icon\" href=\"/static/favicon.ico?v=50afa725b5de8b00030139d09b38620224d4e7dba47c07ef0e86d4643f30c9bfe6bb7e1a4a1c561aa32834480909a4b6fe7cd1e17f7159330b6b5914bf45a880\">\n",
      "    \n",
      "    <link rel=\"stylesheet\" href=\"/static/style/bootstrap.min.css?v=0e8a7fbd6de23ad6b27ab95802a0a0915af6693af612bc304d83af445529ce5d95842309ca3405d10f538d45c8a3a261b8cff78b4bd512dd9effb4109a71d0ab\" />\n",
      "    <link rel=\"stylesheet\" href=\"/static/style/bootstrap-theme.min.css?v=8b2f045cb5b4d5ad346f6e816aa2566829a4f5f2783ec31d80d46a57de8ac0c3d21fe6e53bcd8e1f38ac17fcd06d12088bc9b43e23b5d1da52d10c6b717b22b3\" />\n",
      "    <link rel=\"stylesheet\" href=\"/static/style/index.css?v=30372e3246a801d662cf9e3f9dd656fa192eebde9054a2282449fe43919de9f0ee9b745d7eb49d3b0a5e56357912cc7d776390eddcab9dac85b77bdb17b4bdae\" />\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "<style type=\"text/css\">\n",
      "    /* disable initial hide */\n",
      "    div#header,\n",
      "    div#site {\n",
      "        display: block;\n",
      "    }\n",
      "</style>\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "</head>\n",
      "\n",
      "<body class=\"\"    dir=\"ltr\">\n",
      "\n",
      "  <noscript>\n",
      "    <div id='noscript'>\n",
      "      Jupyter Server requires JavaScript.<br>\n",
      "      Please enable it to proceed. \n",
      "    </div>\n",
      "  </noscript>\n",
      "\n",
      "  <div id=\"header\" role=\"navigation\" aria-label=\"Top Menu\">\n",
      "    <div id=\"header-container\" class=\"container\">\n",
      "      <div id=\"jupyter_server\" class=\"nav navbar-brand\"><a href=\"/lab\" title='dashboard'>\n",
      "          <img src='/static/logo/logo.png?v=a2a176ee3cee251ffddf5fa21fe8e43727a9e5f87a06f9c91ad7b776d9e9d3d5e0159c16cc188a3965e00375fb4bc336c16067c688f5040c0c2d4bfdb852a9e4' alt='Jupyter Server' />\n",
      "        </a></div>\n",
      "\n",
      "      \n",
      "      \n",
      "\n",
      "      \n",
      "      \n",
      "\n",
      "    </div>\n",
      "    <div class=\"header-bar\"></div>\n",
      "\n",
      "    \n",
      "    \n",
      "  </div>\n",
      "\n",
      "  <div id=\"site\">\n",
      "    \n",
      "\n",
      "<div class=\"error\">\n",
      "    \n",
      "    <h1>404 : Not Found</h1>\n",
      "    \n",
      "    \n",
      "<p>You are requesting a page that does not exist!</p>\n",
      "\n",
      "</div>\n",
      "\n",
      "\n",
      "  </div>\n",
      "\n",
      "  \n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "  <script type='text/javascript'>\n",
      "    function _remove_token_from_url() {\n",
      "      if (window.location.search.length <= 1) {\n",
      "        return;\n",
      "      }\n",
      "      var search_parameters = window.location.search.slice(1).split('&');\n",
      "      for (var i = 0; i < search_parameters.length; i++) {\n",
      "        if (search_parameters[i].split('=')[0] === 'token') {\n",
      "          // remote token from search parameters\n",
      "          search_parameters.splice(i, 1);\n",
      "          var new_search = '';\n",
      "          if (search_parameters.length) {\n",
      "            new_search = '?' + search_parameters.join('&');\n",
      "          }\n",
      "          var new_url = window.location.origin +\n",
      "            window.location.pathname +\n",
      "            new_search +\n",
      "            window.location.hash;\n",
      "          window.history.replaceState({}, \"\", new_url);\n",
      "          return;\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    _remove_token_from_url();\n",
      "  </script>\n",
      "</body>\n",
      "\n",
      "* Connection #0 to host localhost left intact\n",
      "</html>"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4434a-d26f-4fea-9296-e200851b65d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa404af-de46-487a-a0ab-92cd1d70443f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2185e5-3a7f-4b77-a1cb-807dc006f1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a051764-4923-41c6-83ff-bb561ab1b8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc30a66-911a-410a-854f-dc3bbc46f410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd6a19-bbe7-4407-bbe1-a870b0e4cc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
